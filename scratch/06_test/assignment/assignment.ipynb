{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5b8ae54",
   "metadata": {},
   "source": [
    "# Assignment 6: Data Wrangling with Merge, Concat, and Reshape\n",
    "\n",
    "**Deliverable:** Completed notebook with output files in `output/`\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, make sure you've generated the data by running `data_generator.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a903027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Verify data files exist\n",
    "required_files = ['data/customers.csv', 'data/products.csv', 'data/purchases.csv']\n",
    "for file in required_files:\n",
    "    if not os.path.exists(file):\n",
    "        raise FileNotFoundError(f\"{file} not found. Run data_generator.ipynb first!\")\n",
    "\n",
    "print(\"✓ All data files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e1edfe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 1: Merging Datasets\n",
    "\n",
    "### Part A: Basic Merge Operations\n",
    "\n",
    "Load the datasets and perform merge operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ec223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the three datasets\n",
    "customers = None  # Load data/customers.csv\n",
    "products = None   # Load data/products.csv\n",
    "purchases = None  # Load data/purchases.csv\n",
    "\n",
    "# Display first few rows of each\n",
    "print(\"Customers:\")\n",
    "display(customers.head())\n",
    "print(\"\\nProducts:\")\n",
    "display(products.head())\n",
    "print(\"\\nPurchases:\")\n",
    "display(purchases.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge purchases with customers (left join)\n",
    "# Keep all purchases, add customer information\n",
    "purchase_customer = None\n",
    "\n",
    "display(purchase_customer.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge the result with products to add product information\n",
    "# Use left join to keep all purchases\n",
    "full_data = None\n",
    "\n",
    "display(full_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2b681",
   "metadata": {},
   "source": [
    "### Part B: Join Type Analysis\n",
    "\n",
    "Compare different join types to understand data relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inner join - only customers who made purchases\n",
    "inner_result = None\n",
    "\n",
    "print(f\"Inner join result: {len(inner_result)} rows\")\n",
    "display(inner_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Left join - all customers (including those with no purchases)\n",
    "left_result = None\n",
    "\n",
    "print(f\"Left join result: {len(left_result)} rows\")\n",
    "display(left_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35858795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find customers who haven't made any purchases\n",
    "# Hint: Use left join and check for NaN values in purchase columns\n",
    "no_purchases = None\n",
    "\n",
    "print(f\"Customers with no purchases: {len(no_purchases)}\")\n",
    "display(no_purchases.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc263b8c",
   "metadata": {},
   "source": [
    "### Part C: Multi-Column Merge\n",
    "\n",
    "Merge on multiple columns when single columns aren't unique enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65764ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create store-specific product pricing\n",
    "# (Different stores may have different prices for same product)\n",
    "store_pricing = pd.DataFrame({\n",
    "    'product_id': ['P001', 'P001', 'P002', 'P002', 'P003', 'P003'],\n",
    "    'store': ['Store A', 'Store B', 'Store A', 'Store B', 'Store A', 'Store B'],\n",
    "    'discount_pct': [5, 10, 8, 5, 0, 15]\n",
    "})\n",
    "\n",
    "# TODO: Merge purchases with store_pricing on BOTH product_id AND store\n",
    "# Hint: Use on=['product_id', 'store']\n",
    "purchases_with_discount = None\n",
    "\n",
    "display(purchases_with_discount.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a51d42",
   "metadata": {},
   "source": [
    "### Part D: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04169d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# TODO: Save full_data to output/q1_merged_data.csv\n",
    "# Hint: Use .to_csv() with index=False\n",
    "\n",
    "print(\"✓ Saved output/q1_merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation report\n",
    "validation_report = f\"\"\"\n",
    "Question 1 Validation Report\n",
    "============================\n",
    "\n",
    "Dataset Sizes:\n",
    "  - Customers: {len(customers)} rows\n",
    "  - Products: {len(products)} rows\n",
    "  - Purchases: {len(purchases)} rows\n",
    "\n",
    "Merge Results:\n",
    "  - Full merged data: {len(full_data)} rows\n",
    "  - Inner join: {len(inner_result)} rows\n",
    "  - Left join: {len(left_result)} rows\n",
    "  - Customers with no purchases: {len(no_purchases)}\n",
    "\n",
    "Data Quality:\n",
    "  - Missing customer names: {full_data['name'].isna().sum()}\n",
    "  - Missing product names: {full_data['product_name'].isna().sum()}\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Save validation_report to output/q1_validation.txt\n",
    "# Hint: Use open() with 'w' mode\n",
    "\n",
    "print(\"✓ Saved output/q1_validation.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e311a7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 2: Concatenating DataFrames\n",
    "\n",
    "### Part A: Vertical Concatenation\n",
    "\n",
    "Combine multiple DataFrames by stacking rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split purchases into quarterly datasets\n",
    "q1_purchases = purchases[purchases['purchase_date'] < '2023-04-01']\n",
    "q2_purchases = purchases[(purchases['purchase_date'] >= '2023-04-01') &\n",
    "                          (purchases['purchase_date'] < '2023-07-01')]\n",
    "q3_purchases = purchases[(purchases['purchase_date'] >= '2023-07-01') &\n",
    "                          (purchases['purchase_date'] < '2023-10-01')]\n",
    "q4_purchases = purchases[purchases['purchase_date'] >= '2023-10-01']\n",
    "\n",
    "print(f\"Q1: {len(q1_purchases)} purchases\")\n",
    "print(f\"Q2: {len(q2_purchases)} purchases\")\n",
    "print(f\"Q3: {len(q3_purchases)} purchases\")\n",
    "print(f\"Q4: {len(q4_purchases)} purchases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Concatenate all quarters back together\n",
    "# Use ignore_index=True for clean sequential indexing\n",
    "# Hint: pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "all_purchases = None\n",
    "\n",
    "print(f\"Total after concat: {len(all_purchases)} purchases\")\n",
    "display(all_purchases.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Concatenate with source tracking using keys parameter\n",
    "# Hint: pd.concat([q1, q2, q3, q4], keys=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "labeled_purchases = None\n",
    "\n",
    "display(labeled_purchases.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ceec1",
   "metadata": {},
   "source": [
    "### Part B: Horizontal Concatenation\n",
    "\n",
    "Add related information as new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ec9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer satisfaction scores (subset of customers)\n",
    "satisfaction = pd.DataFrame({\n",
    "    'customer_id': customers['customer_id'].sample(50, random_state=42),\n",
    "    'satisfaction_score': np.random.randint(1, 11, size=50),\n",
    "    'survey_date': pd.date_range('2023-12-01', periods=50, freq='D')\n",
    "})\n",
    "\n",
    "# Create customer loyalty tier (different subset)\n",
    "loyalty = pd.DataFrame({\n",
    "    'customer_id': customers['customer_id'].sample(60, random_state=123),\n",
    "    'tier': np.random.choice(['Bronze', 'Silver', 'Gold', 'Platinum'], size=60),\n",
    "    'points': np.random.randint(100, 10000, size=60)\n",
    "})\n",
    "\n",
    "# Set customer_id as index for both\n",
    "satisfaction = satisfaction.set_index('customer_id')\n",
    "loyalty = loyalty.set_index('customer_id')\n",
    "\n",
    "print(\"Satisfaction scores:\")\n",
    "display(satisfaction.head())\n",
    "print(\"\\nLoyalty tiers:\")\n",
    "display(loyalty.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e682e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Horizontal concat to combine satisfaction and loyalty\n",
    "# Use outer join to keep all customers from both datasets\n",
    "# Hint: pd.concat([df1, df2], axis=1, join='outer')\n",
    "customer_metrics = None\n",
    "\n",
    "display(customer_metrics.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle misaligned indexes - how many NaN values?\n",
    "print(f\"Missing satisfaction scores: {customer_metrics['satisfaction_score'].isna().sum()}\")\n",
    "print(f\"Missing loyalty tiers: {customer_metrics['tier'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12667976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save customer_metrics to output/q2_combined_data.csv\n",
    "# Hint: Use .to_csv() - index will be saved automatically\n",
    "\n",
    "print(\"✓ Saved output/q2_combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d072ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 3: Reshaping and Analysis\n",
    "\n",
    "### Part A: Pivot Table Analysis\n",
    "\n",
    "Transform data to analyze patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0540af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge purchases with products to get categories\n",
    "purchases_categorized = pd.merge(purchases, products[['product_id', 'category']],\n",
    "                                  on='product_id')\n",
    "\n",
    "# Add month column for grouping\n",
    "purchases_categorized['month'] = pd.to_datetime(purchases_categorized['purchase_date']).dt.to_period('M')\n",
    "\n",
    "display(purchases_categorized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c2b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create pivot table - sales by category and month\n",
    "# Use pivot_table to handle duplicate entries (aggregate with sum)\n",
    "# Hint: pd.pivot_table(df, values='total_price', index='month', columns='category', aggfunc='sum')\n",
    "sales_pivot = None\n",
    "\n",
    "display(sales_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cca257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save sales_pivot to output/q3_category_sales_wide.csv\n",
    "# Hint: Use .to_csv()\n",
    "\n",
    "print(\"✓ Saved output/q3_category_sales_wide.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115497f3",
   "metadata": {},
   "source": [
    "### Part B: Melt and Long Format\n",
    "\n",
    "Convert wide format back to long for different analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ec7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to make month a column\n",
    "sales_wide = sales_pivot.reset_index()\n",
    "\n",
    "# TODO: Melt to convert category columns back to rows\n",
    "# Hint: pd.melt(df, id_vars=['month'], var_name='category', value_name='sales')\n",
    "sales_long = None\n",
    "\n",
    "display(sales_long.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate summary statistics using the long format\n",
    "# Group by category and calculate total sales, average monthly sales\n",
    "# Hint: Use .groupby('category')['sales'].agg(['sum', 'mean']) and sort by sum descending\n",
    "category_summary = None\n",
    "\n",
    "display(category_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6da258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final analysis report\n",
    "analysis_report = f\"\"\"\n",
    "Question 3 Analysis Report\n",
    "==========================\n",
    "\n",
    "Sales by Category (Total):\n",
    "{category_summary.to_string()}\n",
    "\n",
    "Time Period:\n",
    "  - Start: {purchases['purchase_date'].min()}\n",
    "  - End: {purchases['purchase_date'].max()}\n",
    "  - Months: {purchases_categorized['month'].nunique()}\n",
    "\n",
    "Top Category: {category_summary.index[0]}\n",
    "Bottom Category: {category_summary.index[-1]}\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Save analysis_report to output/q3_analysis_report.txt\n",
    "# Hint: Use open() with 'w' mode\n",
    "\n",
    "print(\"✓ Saved output/q3_analysis_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e971b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, verify you've created:\n",
    "\n",
    "- [ ] `output/q1_merged_data.csv` - Merged customer/product/purchase data\n",
    "- [ ] `output/q1_validation.txt` - Merge validation report\n",
    "- [ ] `output/q2_combined_data.csv` - Concatenated data with metrics\n",
    "- [ ] `output/q3_category_sales_wide.csv` - Pivoted category sales\n",
    "- [ ] `output/q3_analysis_report.txt` - Sales analysis report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbd14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check all outputs exist\n",
    "required_outputs = [\n",
    "    'output/q1_merged_data.csv',\n",
    "    'output/q1_validation.txt',\n",
    "    'output/q2_combined_data.csv',\n",
    "    'output/q3_category_sales_wide.csv',\n",
    "    'output/q3_analysis_report.txt'\n",
    "]\n",
    "\n",
    "print(\"Checking required outputs:\")\n",
    "for file in required_outputs:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {file}\")\n",
    "\n",
    "all_exist = all(os.path.exists(f) for f in required_outputs)\n",
    "if all_exist:\n",
    "    print(\"\\n✓ All required files created! Ready to submit.\")\n",
    "else:\n",
    "    print(\"\\n✗ Some files are missing. Review the questions above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
