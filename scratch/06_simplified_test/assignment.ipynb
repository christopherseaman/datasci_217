{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27cb2e46",
   "metadata": {},
   "source": [
    "# Assignment 6: Data Wrangling with Merge, Concat, and Reshape\n",
    "\n",
    "**Deliverable:** Completed notebook with output files in `output/`\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, make sure you've generated the data by running `data_generator.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Verify data files exist\n",
    "required_files = ['data/customers.csv', 'data/products.csv', 'data/purchases.csv']\n",
    "for file in required_files:\n",
    "    if not os.path.exists(file):\n",
    "        raise FileNotFoundError(f\"{file} not found. Run data_generator.ipynb first!\")\n",
    "\n",
    "print(\"✓ All data files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a454b31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dataset Column Reference\n",
    "\n",
    "**`customers.csv` columns:**\n",
    "- `customer_id` - Unique ID (C001, C002, ...)\n",
    "- `name` - Customer full name\n",
    "- `city` - Customer city\n",
    "- `signup_date` - Registration date\n",
    "\n",
    "**`products.csv` columns:**\n",
    "- `product_id` - Unique ID (P001, P002, ...)\n",
    "- `product_name` - Product name\n",
    "- `category` - Product category (Electronics, Clothing, Home & Garden, Books, Sports)\n",
    "- `price` - Product price in dollars\n",
    "\n",
    "**`purchases.csv` columns:**\n",
    "- `purchase_id` - Unique ID (T0001, T0002, ...)\n",
    "- `customer_id` - Links to customers\n",
    "- `product_id` - Links to products\n",
    "- `quantity` - Number of items purchased\n",
    "- `purchase_date` - Purchase date\n",
    "- `store` - Store location (Store A, B, or C)\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1: Merging Datasets\n",
    "\n",
    "### Part A: Basic Merge Operations\n",
    "\n",
    "Load the datasets and perform merge operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the three datasets\n",
    "customers = None  # Load data/customers.csv\n",
    "products = None   # Load data/products.csv\n",
    "purchases = None  # Load data/purchases.csv\n",
    "\n",
    "# Display first few rows of each\n",
    "print(\"Customers:\")\n",
    "display(customers.head())\n",
    "print(\"\\nProducts:\")\n",
    "display(products.head())\n",
    "print(\"\\nPurchases:\")\n",
    "display(purchases.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1870097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge purchases with customers (left join)\n",
    "# Keep all purchases, add customer information\n",
    "purchase_customer = None\n",
    "\n",
    "display(purchase_customer.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge the result with products to add product information\n",
    "# Use left join to keep all purchases\n",
    "full_data = None\n",
    "\n",
    "display(full_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate total_price for each purchase\n",
    "# Multiply quantity by price to get the total cost\n",
    "# Round to 2 decimal places\n",
    "# Hint: full_data['total_price'] = (full_data['quantity'] * full_data['price']).round(2)\n",
    "\n",
    "display(full_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2cf1bd",
   "metadata": {},
   "source": [
    "### Part B: Join Type Analysis\n",
    "\n",
    "Compare different join types to understand data relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea884524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inner join - only customers who made purchases\n",
    "inner_result = None\n",
    "\n",
    "print(f\"Inner join result: {len(inner_result)} rows\")\n",
    "display(inner_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Left join - all customers (including those with no purchases)\n",
    "left_result = None\n",
    "\n",
    "print(f\"Left join result: {len(left_result)} rows\")\n",
    "display(left_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d963939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find customers who haven't made any purchases\n",
    "# Hint: Use left join result and check where purchase_id is NaN\n",
    "# Use .isna() to find NaN values: left_result[left_result['purchase_id'].isna()]\n",
    "no_purchases = None\n",
    "\n",
    "print(f\"Customers with no purchases: {len(no_purchases)}\")\n",
    "display(no_purchases.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bb673",
   "metadata": {},
   "source": [
    "### Part C: Multi-Column Merge\n",
    "\n",
    "Merge on multiple columns when single columns aren't unique enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create store-specific product pricing\n",
    "# (Different stores may have different prices for same product)\n",
    "store_pricing = pd.DataFrame({\n",
    "    'product_id': ['P001', 'P001', 'P002', 'P002', 'P003', 'P003'],\n",
    "    'store': ['Store A', 'Store B', 'Store A', 'Store B', 'Store A', 'Store B'],\n",
    "    'discount_pct': [5, 10, 8, 5, 0, 15]\n",
    "})\n",
    "\n",
    "# TODO: Merge purchases with store_pricing on BOTH product_id AND store\n",
    "# Hint: Use on=['product_id', 'store']\n",
    "purchases_with_discount = None\n",
    "\n",
    "display(purchases_with_discount.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abac3283",
   "metadata": {},
   "source": [
    "### Part D: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b358046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# TODO: Save full_data to output/q1_merged_data.csv\n",
    "# Hint: Use .to_csv() with index=False\n",
    "\n",
    "print(\"✓ Saved output/q1_merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c1457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation report\n",
    "validation_report = f\"\"\"\n",
    "Question 1 Validation Report\n",
    "============================\n",
    "\n",
    "Dataset Sizes:\n",
    "  - Customers: {len(customers)} rows\n",
    "  - Products: {len(products)} rows\n",
    "  - Purchases: {len(purchases)} rows\n",
    "\n",
    "Merge Results:\n",
    "  - Full merged data: {len(full_data)} rows\n",
    "  - Inner join: {len(inner_result)} rows\n",
    "  - Left join: {len(left_result)} rows\n",
    "  - Customers with no purchases: {len(no_purchases)}\n",
    "\n",
    "Data Quality:\n",
    "  - Missing customer names: {full_data['name'].isna().sum()}\n",
    "  - Missing product names: {full_data['product_name'].isna().sum()}\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Save validation_report to output/q1_validation.txt\n",
    "# Hint: Use open() with 'w' mode\n",
    "\n",
    "print(\"✓ Saved output/q1_validation.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9314f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 2: Concatenating DataFrames\n",
    "\n",
    "### Part A: Vertical Concatenation\n",
    "\n",
    "Combine multiple DataFrames by stacking rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688edc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split purchases into quarterly datasets\n",
    "q1_purchases = purchases[purchases['purchase_date'] < '2023-04-01']\n",
    "q2_purchases = purchases[(purchases['purchase_date'] >= '2023-04-01') &\n",
    "                          (purchases['purchase_date'] < '2023-07-01')]\n",
    "q3_purchases = purchases[(purchases['purchase_date'] >= '2023-07-01') &\n",
    "                          (purchases['purchase_date'] < '2023-10-01')]\n",
    "q4_purchases = purchases[purchases['purchase_date'] >= '2023-10-01']\n",
    "\n",
    "print(f\"Q1: {len(q1_purchases)} purchases\")\n",
    "print(f\"Q2: {len(q2_purchases)} purchases\")\n",
    "print(f\"Q3: {len(q3_purchases)} purchases\")\n",
    "print(f\"Q4: {len(q4_purchases)} purchases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Concatenate all quarters back together\n",
    "# Use ignore_index=True for clean sequential indexing\n",
    "# Hint: pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "all_purchases = None\n",
    "\n",
    "print(f\"Total after concat: {len(all_purchases)} purchases\")\n",
    "display(all_purchases.head())\n",
    "print(f\"\\nVerify total rows: {len(q1_purchases)} + {len(q2_purchases)} + {len(q3_purchases)} + {len(q4_purchases)} = {len(all_purchases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3719e0e",
   "metadata": {},
   "source": [
    "### Part B: Horizontal Concatenation\n",
    "\n",
    "Add related information as new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customer satisfaction scores (subset of customers)\n",
    "satisfaction = pd.DataFrame({\n",
    "    'customer_id': customers['customer_id'].sample(50, random_state=42),\n",
    "    'satisfaction_score': np.random.randint(1, 11, size=50),\n",
    "    'survey_date': pd.date_range('2023-12-01', periods=50, freq='D')\n",
    "})\n",
    "\n",
    "# Create customer loyalty tier (different subset)\n",
    "loyalty = pd.DataFrame({\n",
    "    'customer_id': customers['customer_id'].sample(60, random_state=123),\n",
    "    'tier': np.random.choice(['Bronze', 'Silver', 'Gold', 'Platinum'], size=60),\n",
    "    'points': np.random.randint(100, 10000, size=60)\n",
    "})\n",
    "\n",
    "# Set customer_id as index for both\n",
    "satisfaction = satisfaction.set_index('customer_id')\n",
    "loyalty = loyalty.set_index('customer_id')\n",
    "\n",
    "print(\"Satisfaction scores:\")\n",
    "display(satisfaction.head())\n",
    "print(\"\\nLoyalty tiers:\")\n",
    "display(loyalty.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bcded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Horizontal concat to combine satisfaction and loyalty\n",
    "# Use outer join to keep all customers from both datasets\n",
    "# Hint: pd.concat([df1, df2], axis=1, join='outer')\n",
    "customer_metrics = None\n",
    "\n",
    "display(customer_metrics.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601da2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle misaligned indexes - how many NaN values?\n",
    "print(f\"Missing satisfaction scores: {customer_metrics['satisfaction_score'].isna().sum()}\")\n",
    "print(f\"Missing loyalty tiers: {customer_metrics['tier'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781fd3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save customer_metrics to output/q2_combined_data.csv\n",
    "# Hint: Use .to_csv() - index will be saved automatically\n",
    "\n",
    "print(\"✓ Saved output/q2_combined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb43cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 3: Reshaping and Analysis\n",
    "\n",
    "### Part A: Pivot Table Analysis\n",
    "\n",
    "Transform data to analyze patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the merged data from Question 1\n",
    "# This already has purchases merged with customers and products (and total_price calculated)\n",
    "# Hint: pd.read_csv('output/q1_merged_data.csv')\n",
    "full_data = None\n",
    "\n",
    "# Add month column for grouping (YYYY-MM format like \"2023-01\")\n",
    "full_data['month'] = pd.to_datetime(full_data['purchase_date']).dt.strftime('%Y-%m')\n",
    "\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create pivot table - sales by category and month\n",
    "# Use pivot_table to handle duplicate entries (aggregate with sum)\n",
    "# Hint: pd.pivot_table(df, values='total_price', index='month', columns='category', aggfunc='sum')\n",
    "sales_pivot = None\n",
    "\n",
    "display(sales_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cc005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save sales_pivot to output/q3_category_sales_wide.csv\n",
    "# Hint: Use .to_csv()\n",
    "\n",
    "print(\"✓ Saved output/q3_category_sales_wide.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d96952",
   "metadata": {},
   "source": [
    "### Part B: Melt and Long Format\n",
    "\n",
    "Convert wide format back to long for different analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc407a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to make month a column\n",
    "sales_wide = sales_pivot.reset_index()\n",
    "\n",
    "# TODO: Melt to convert category columns back to rows\n",
    "# Hint: pd.melt(df, id_vars=['month'], var_name='category', value_name='sales')\n",
    "sales_long = None\n",
    "\n",
    "display(sales_long.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c02108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate summary statistics using the long format\n",
    "# Group by category and calculate total sales, average monthly sales\n",
    "# Hint: Use .groupby('category')['sales'].agg(['sum', 'mean']) and sort by sum descending\n",
    "category_summary = None\n",
    "\n",
    "display(category_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final analysis report\n",
    "analysis_report = f\"\"\"\n",
    "Question 3 Analysis Report\n",
    "==========================\n",
    "\n",
    "Sales by Category (Total):\n",
    "{category_summary.to_string()}\n",
    "\n",
    "Time Period:\n",
    "  - Start: {full_data['purchase_date'].min()}\n",
    "  - End: {full_data['purchase_date'].max()}\n",
    "  - Months: {full_data['month'].nunique()}\n",
    "\n",
    "Top Category: {category_summary.index[0]}\n",
    "Bottom Category: {category_summary.index[-1]}\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Save analysis_report to output/q3_analysis_report.txt\n",
    "# Hint: Use open() with 'w' mode\n",
    "\n",
    "print(\"✓ Saved output/q3_analysis_report.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb96d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, verify you've created:\n",
    "\n",
    "- [ ] `output/q1_merged_data.csv` - Merged customer/product/purchase data\n",
    "- [ ] `output/q1_validation.txt` - Merge validation report\n",
    "- [ ] `output/q2_combined_data.csv` - Concatenated data with metrics\n",
    "- [ ] `output/q3_category_sales_wide.csv` - Pivoted category sales\n",
    "- [ ] `output/q3_analysis_report.txt` - Sales analysis report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check all outputs exist\n",
    "required_outputs = [\n",
    "    'output/q1_merged_data.csv',\n",
    "    'output/q1_validation.txt',\n",
    "    'output/q2_combined_data.csv',\n",
    "    'output/q3_category_sales_wide.csv',\n",
    "    'output/q3_analysis_report.txt'\n",
    "]\n",
    "\n",
    "print(\"Checking required outputs:\")\n",
    "for file in required_outputs:\n",
    "    exists = os.path.exists(file)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {file}\")\n",
    "\n",
    "all_exist = all(os.path.exists(f) for f in required_outputs)\n",
    "if all_exist:\n",
    "    print(\"\\n✓ All required files created! Ready to submit.\")\n",
    "else:\n",
    "    print(\"\\n✗ Some files are missing. Review the questions above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
