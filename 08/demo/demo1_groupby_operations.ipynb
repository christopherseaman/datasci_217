{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa252f47",
   "metadata": {},
   "source": [
    "# Demo 1: GroupBy Operations\n",
    "\n",
    "## Learning Objectives\n",
    "- Master the split-apply-combine paradigm\n",
    "- Apply aggregation functions to grouped data\n",
    "- Use transform, filter, and apply operations\n",
    "- Handle hierarchical grouping\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7af078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set inline plotting for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd232adb",
   "metadata": {},
   "source": [
    "## Part 1: Basic GroupBy Operations\n",
    "\n",
    "### Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a41299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample sales data\n",
    "data = {\n",
    "    'Department': ['Sales', 'Sales', 'Engineering', 'Engineering', 'Marketing', 'Marketing'],\n",
    "    'Employee': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank'],\n",
    "    'Salary': [50000, 55000, 80000, 85000, 60000, 65000],\n",
    "    'Experience': [2, 3, 5, 7, 4, 6],\n",
    "    'Region': ['North', 'South', 'North', 'South', 'North', 'South']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample Data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94623060",
   "metadata": {},
   "source": [
    "### Basic Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ced85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by department and calculate statistics\n",
    "print(\"=== Basic Aggregation ===\")\n",
    "print(\"Mean salary by department:\")\n",
    "print(df.groupby('Department')['Salary'].mean())\n",
    "\n",
    "print(\"\\nMultiple aggregations:\")\n",
    "print(df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'sum', 'count'],\n",
    "    'Experience': 'mean'\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953b615",
   "metadata": {},
   "source": [
    "### GroupBy with Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns\n",
    "print(\"=== Multi-column Grouping ===\")\n",
    "result = df.groupby(['Department', 'Region']).agg({\n",
    "    'Salary': 'mean',\n",
    "    'Experience': 'mean'\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee935cd",
   "metadata": {},
   "source": [
    "## Part 2: Advanced GroupBy Operations\n",
    "\n",
    "### Transform Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform: Add group statistics as new columns\n",
    "print(\"=== Transform Operations ===\")\n",
    "df['Salary_Mean'] = df.groupby('Department')['Salary'].transform('mean')\n",
    "df['Salary_Std'] = df.groupby('Department')['Salary'].transform('std')\n",
    "df['Salary_Normalized'] = df.groupby('Department')['Salary'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "print(\"Data with group statistics:\")\n",
    "print(df[['Department', 'Employee', 'Salary', 'Salary_Mean', 'Salary_Std', 'Salary_Normalized']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95832242",
   "metadata": {},
   "source": [
    "### Filter Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83428622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: Keep only departments with more than 1 employee\n",
    "print(\"=== Filter Operations ===\")\n",
    "filtered = df.groupby('Department').filter(lambda x: len(x) > 1)\n",
    "print(\"Departments with multiple employees:\")\n",
    "print(filtered)\n",
    "\n",
    "# Filter: Keep only departments with average salary > 60000\n",
    "high_salary_depts = df.groupby('Department').filter(lambda x: x['Salary'].mean() > 60000)\n",
    "print(\"\\nHigh-salary departments:\")\n",
    "print(high_salary_depts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd897dc",
   "metadata": {},
   "source": [
    "### Apply Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply: Custom function for salary statistics\n",
    "def salary_stats(group):\n",
    "    return pd.Series({\n",
    "        'count': len(group),\n",
    "        'mean': group['Salary'].mean(),\n",
    "        'std': group['Salary'].std(),\n",
    "        'range': group['Salary'].max() - group['Salary'].min()\n",
    "    })\n",
    "\n",
    "print(\"=== Apply Operations ===\")\n",
    "print(\"Custom statistics by department:\")\n",
    "print(df.groupby('Department').apply(salary_stats))\n",
    "\n",
    "# Apply: Get top earners in each department\n",
    "top_earners = df.groupby('Department').apply(lambda x: x.nlargest(1, 'Salary'))\n",
    "print(\"\\nTop earners per department:\")\n",
    "print(top_earners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1747f3",
   "metadata": {},
   "source": [
    "## Part 3: Hierarchical Grouping\n",
    "\n",
    "### Multi-level Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa17ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hierarchical data\n",
    "hierarchical_data = {\n",
    "    'Region': ['North', 'North', 'South', 'South', 'North', 'South'],\n",
    "    'Department': ['Sales', 'Engineering', 'Sales', 'Engineering', 'Marketing', 'Marketing'],\n",
    "    'Revenue': [100000, 150000, 120000, 180000, 80000, 90000],\n",
    "    'Employees': [5, 8, 6, 10, 4, 5]\n",
    "}\n",
    "\n",
    "hierarchical_df = pd.DataFrame(hierarchical_data)\n",
    "print(\"=== Hierarchical Grouping ===\")\n",
    "print(\"Original data:\")\n",
    "print(hierarchical_df)\n",
    "\n",
    "# Hierarchical grouping\n",
    "hierarchical_grouped = hierarchical_df.groupby(['Region', 'Department']).sum()\n",
    "print(\"\\nHierarchical grouping:\")\n",
    "print(hierarchical_grouped)\n",
    "\n",
    "# Unstack to wide format\n",
    "wide_format = hierarchical_grouped.unstack()\n",
    "print(\"\\nWide format:\")\n",
    "print(wide_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88ab74",
   "metadata": {},
   "source": [
    "### MultiIndex Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with MultiIndex\n",
    "print(\"=== MultiIndex Operations ===\")\n",
    "print(\"Index levels:\", hierarchical_grouped.index.names)\n",
    "print(\"Index values:\", hierarchical_grouped.index.values)\n",
    "\n",
    "# Access specific groups\n",
    "print(\"\\nNorth region data:\")\n",
    "print(hierarchical_grouped.loc['North'])\n",
    "\n",
    "# Reset index to flatten\n",
    "flattened = hierarchical_grouped.reset_index()\n",
    "print(\"\\nFlattened data:\")\n",
    "print(flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531db45",
   "metadata": {},
   "source": [
    "## Part 4: Real-world Example\n",
    "\n",
    "### Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more realistic sales data\n",
    "np.random.seed(42)\n",
    "n_sales = 1000\n",
    "\n",
    "sales_data = {\n",
    "    'Date': pd.date_range('2023-01-01', periods=n_sales, freq='D'),\n",
    "    'Product': np.random.choice(['A', 'B', 'C', 'D'], n_sales),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], n_sales),\n",
    "    'Salesperson': np.random.choice(['Alice', 'Bob', 'Charlie', 'Diana'], n_sales),\n",
    "    'Quantity': np.random.randint(1, 10, n_sales),\n",
    "    'Unit_Price': np.random.uniform(10, 100, n_sales)\n",
    "}\n",
    "\n",
    "sales_df = pd.DataFrame(sales_data)\n",
    "sales_df['Total_Sales'] = sales_df['Quantity'] * sales_df['Unit_Price']\n",
    "\n",
    "print(\"=== Sales Analysis ===\")\n",
    "print(\"Sample sales data:\")\n",
    "print(sales_df.head())\n",
    "\n",
    "# Monthly sales by region\n",
    "monthly_sales = sales_df.groupby([sales_df['Date'].dt.to_period('M'), 'Region'])['Total_Sales'].sum()\n",
    "print(\"\\nMonthly sales by region:\")\n",
    "print(monthly_sales.head(10))\n",
    "\n",
    "# Top salesperson by region\n",
    "top_salesperson = sales_df.groupby('Region').apply(\n",
    "    lambda x: x.groupby('Salesperson')['Total_Sales'].sum().idxmax()\n",
    ")\n",
    "print(\"\\nTop salesperson by region:\")\n",
    "print(top_salesperson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111c2354",
   "metadata": {},
   "source": [
    "### Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83111d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "print(\"=== Performance Analysis ===\")\n",
    "\n",
    "# Method 1: Multiple groupby operations\n",
    "start_time = pd.Timestamp.now()\n",
    "result1 = sales_df.groupby('Region')['Total_Sales'].sum()\n",
    "result2 = sales_df.groupby('Region')['Quantity'].sum()\n",
    "end_time = pd.Timestamp.now()\n",
    "method1_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Method 2: Single groupby with multiple aggregations\n",
    "start_time = pd.Timestamp.now()\n",
    "result3 = sales_df.groupby('Region').agg({\n",
    "    'Total_Sales': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "})\n",
    "end_time = pd.Timestamp.now()\n",
    "method2_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"Method 1 (multiple groupby): {method1_time:.6f} seconds\")\n",
    "print(f\"Method 2 (single groupby): {method2_time:.6f} seconds\")\n",
    "print(f\"Performance improvement: {method1_time/method2_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec12176",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Split-Apply-Combine**: The fundamental pattern of data aggregation\n",
    "2. **Aggregation Functions**: Use mean, sum, count, and custom functions\n",
    "3. **Transform Operations**: Add group statistics to original data\n",
    "4. **Filter Operations**: Remove groups based on conditions\n",
    "5. **Apply Operations**: Use custom functions on groups\n",
    "6. **Hierarchical Grouping**: Work with multi-level group structures\n",
    "7. **Performance**: Single groupby with multiple aggregations is more efficient\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Practice with your own datasets\n",
    "- Experiment with different aggregation functions\n",
    "- Learn about pivot tables for multi-dimensional analysis\n",
    "- Explore remote computing for large datasets"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
