{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d4dbdea",
   "metadata": {},
   "source": [
    "# Assignment 10: Modeling Fundamentals\n",
    "\n",
    "Complete the following three questions to demonstrate your understanding of statistical modeling, machine learning, and gradient boosting.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeddde37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6047b91",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California Housing dataset from scikit-learn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Fetch the dataset\n",
    "housing_data = fetch_california_housing(as_frame=True)\n",
    "df = housing_data.frame\n",
    "\n",
    "# Rename target for clarity\n",
    "df = df.rename(columns={\"MedHouseVal\": \"house_value\"})\n",
    "\n",
    "print(f\"Loaded {len(df)} housing records\")\n",
    "print(\"\\nFeature names:\", housing_data.feature_names)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e07a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 1: Statistical Modeling with statsmodels\n",
    "\n",
    "**Note:** This question focuses on statistical modeling for inference - understanding relationships between variables. We'll use a subset of features (`MedInc`, `AveBedrms`, `Population`) to focus on interpretability and statistical significance rather than maximizing prediction accuracy. The `statsmodels` library provides detailed statistical information (p-values, confidence intervals, AIC) that helps us understand *why* variables are related.\n",
    "\n",
    "**Why a subset of features?** In statistical modeling, we often use fewer features to maintain interpretability and focus on understanding relationships. This contrasts with machine learning (Question 2), where we use all available features to maximize prediction accuracy.\n",
    "\n",
    "**Objective:** Fit linear regression models using `statsmodels`, extract statistical information, and compare models with and without interaction terms.\n",
    "\n",
    "### Part 1.1: Fit the Model\n",
    "\n",
    "Fit a linear regression model predicting `house_value` from `MedInc`, `AveBedrms`, and `Population` using the formula API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit a linear regression model using statsmodels formula API\n",
    "# Hint: Use smf.ols() with the formula 'house_value ~ MedInc + AveBedrms + Population'\n",
    "# Don't forget to call .fit() on the model\n",
    "\n",
    "model = None  # Replace None with your code\n",
    "results = None  # Replace None with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad3971",
   "metadata": {},
   "source": [
    "### Part 1.2: Extract Model Summary\n",
    "\n",
    "Print the model summary and save key statistics to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0104e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the model summary\n",
    "# Use: results.summary()\n",
    "\n",
    "print(\"=== Model Summary ===\")\n",
    "# Your code here\n",
    "\n",
    "# TODO: Extract p-values for coefficients\n",
    "# Use: results.pvalues to get p-values for each coefficient\n",
    "# Print which coefficients are statistically significant (p < 0.05)\n",
    "\n",
    "pvalues = None  # Replace None with your code\n",
    "print(\"\\n=== Coefficient Significance (p-values) ===\")\n",
    "# Your code here to print p-values and identify significant coefficients\n",
    "\n",
    "# TODO: Save key statistics to output file\n",
    "# Extract: R-squared, number of observations, and AIC (Akaike Information Criterion)\n",
    "# Format: \"R-squared: X.XXXX\\nObservations: XXXX\\nAIC: XXXXX.XX\"\n",
    "\n",
    "with open(\"output/q1_model_summary.txt\", \"w\") as f:\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355071a0",
   "metadata": {},
   "source": [
    "### Part 1.3: Make Predictions\n",
    "\n",
    "Make predictions for all houses and save to CSV.\n",
    "\n",
    "**Note:** In statistical modeling, we often make predictions on the full dataset to understand model fit. This differs from machine learning (Question 2), where we use train/test splits to evaluate generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions using the fitted model\n",
    "# Hint: Use results.predict() with a DataFrame containing the features used in the model\n",
    "# The features are: MedInc, AveBedrms, Population\n",
    "# Save predictions along with actual values to CSV\n",
    "\n",
    "predictions = None  # Replace None with your code\n",
    "\n",
    "# Create DataFrame with predictions\n",
    "pred_df = pd.DataFrame({\n",
    "    \"actual_value\": df[\"house_value\"],\n",
    "    \"predicted_value\": predictions,\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "pred_df.to_csv(\"output/q1_statistical_model.csv\", index=False)\n",
    "print(f\"\\nSaved {len(pred_df)} predictions to output/q1_statistical_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053bf61",
   "metadata": {},
   "source": [
    "### Part 1.4: Model with Interaction Term\n",
    "\n",
    "Now let's fit a model with an interaction term. An **interaction term** allows the effect of one variable to depend on the value of another variable. For example, the effect of income (`MedInc`) on house value might depend on the number of bedrooms (`AveBedrms`). In the formula API, we use `*` to include both main effects and their interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c296d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit a model with an interaction term between MedInc and AveBedrms\n",
    "# Hint: Use formula 'house_value ~ MedInc + AveBedrms + Population + MedInc:AveBedrms'\n",
    "# Or use 'house_value ~ MedInc * AveBedrms + Population' (the * includes both main effects and interaction)\n",
    "\n",
    "model_interaction = None  # Replace None with your code\n",
    "results_interaction = None  # Replace None with your code\n",
    "\n",
    "print(\"\\n=== Model with Interaction Term ===\")\n",
    "# Your code here to print the summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83bc2c1",
   "metadata": {},
   "source": [
    "### Part 1.5: Compare Models\n",
    "\n",
    "Compare the two models using AIC (Akaike Information Criterion). Lower AIC indicates a better model (accounting for model complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10941b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare the two models using AIC\n",
    "# Extract AIC from both models: results.aic and results_interaction.aic\n",
    "# Determine which model is better (lower AIC is better)\n",
    "\n",
    "aic_simple = None  # Replace None with your code\n",
    "aic_interaction = None  # Replace None with your code\n",
    "\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"Simple model AIC: {aic_simple:.2f}\")\n",
    "print(f\"Interaction model AIC: {aic_interaction:.2f}\")\n",
    "# Your code here to determine and print which model is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e744c660",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 2: Machine Learning with scikit-learn\n",
    "\n",
    "**Note:** While Question 1 focused on statistical inference (understanding relationships and testing hypotheses), Question 2 focuses on machine learning for prediction. We'll use all available features to maximize prediction accuracy rather than focusing on interpretability.\n",
    "\n",
    "**Objective:** Fit and compare linear regression and random forest models using `scikit-learn`.\n",
    "\n",
    "### Part 2.1: Prepare Data\n",
    "\n",
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare features and target\n",
    "# Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
    "# Target: 'house_value'\n",
    "\n",
    "feature_cols = [\n",
    "    \"MedInc\",\n",
    "    \"HouseAge\",\n",
    "    \"AveRooms\",\n",
    "    \"AveBedrms\",\n",
    "    \"Population\",\n",
    "    \"AveOccup\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "]\n",
    "X = None  # Replace None with your code\n",
    "y = None  # Replace None with your code\n",
    "\n",
    "# TODO: Split into train and test sets (80/20 split, random_state=42)\n",
    "X_train, X_test, y_train, y_test = None  # Replace None with your code\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c89cb",
   "metadata": {},
   "source": [
    "### Part 2.2: Fit Linear Regression\n",
    "\n",
    "Fit a linear regression model and evaluate it on both training and test sets. Comparing train and test performance helps us detect overfitting - if the model performs much better on training data than test data, it's likely overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit a LinearRegression model\n",
    "lr_model = None  # Replace None with your code\n",
    "# Your code here\n",
    "\n",
    "# TODO: Make predictions on both training and test sets\n",
    "lr_train_pred = None  # Replace None with your code\n",
    "lr_test_pred = None  # Replace None with your code\n",
    "\n",
    "# Calculate metrics on both sets\n",
    "lr_train_r2 = r2_score(y_train, lr_train_pred)\n",
    "lr_test_r2 = r2_score(y_test, lr_test_pred)\n",
    "lr_train_rmse = np.sqrt(mean_squared_error(y_train, lr_train_pred))\n",
    "lr_test_rmse = np.sqrt(mean_squared_error(y_test, lr_test_pred))\n",
    "\n",
    "print(\"=== Linear Regression Results ===\")\n",
    "print(f\"Training - R²: {lr_train_r2:.4f}, RMSE: {lr_train_rmse:.2f}\")\n",
    "print(f\"Test - R²: {lr_test_r2:.4f}, RMSE: {lr_test_rmse:.2f}\")\n",
    "\n",
    "# Store test predictions for later use\n",
    "lr_pred = lr_test_pred\n",
    "lr_r2 = lr_test_r2\n",
    "lr_rmse = lr_test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036c8bd",
   "metadata": {},
   "source": [
    "### Part 2.3: Fit Random Forest\n",
    "\n",
    "Fit a random forest model and evaluate it on both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit a RandomForestRegressor model\n",
    "# Use: n_estimators=50, max_depth=8, random_state=42\n",
    "rf_model = None  # Replace None with your code\n",
    "# Your code here\n",
    "\n",
    "# TODO: Make predictions on both training and test sets\n",
    "rf_train_pred = None  # Replace None with your code\n",
    "rf_test_pred = None  # Replace None with your code\n",
    "\n",
    "# Calculate metrics on both sets\n",
    "rf_train_r2 = r2_score(y_train, rf_train_pred)\n",
    "rf_test_r2 = r2_score(y_test, rf_test_pred)\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_train_pred))\n",
    "rf_test_rmse = np.sqrt(mean_squared_error(y_test, rf_test_pred))\n",
    "\n",
    "print(\"=== Random Forest Results ===\")\n",
    "print(f\"Training - R²: {rf_train_r2:.4f}, RMSE: {rf_train_rmse:.2f}\")\n",
    "print(f\"Test - R²: {rf_test_r2:.4f}, RMSE: {rf_test_rmse:.2f}\")\n",
    "\n",
    "# Store test predictions and metrics for later use\n",
    "rf_pred = rf_test_pred\n",
    "rf_r2 = rf_test_r2\n",
    "rf_rmse = rf_test_rmse\n",
    "\n",
    "# TODO: Extract feature importance for later comparison\n",
    "# Use: rf_model.feature_importances_\n",
    "rf_feature_importance = None  # Replace None with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07dec4",
   "metadata": {},
   "source": [
    "### Part 2.4: Save Predictions and Comparison\n",
    "\n",
    "Save predictions and model comparison to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610aef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save predictions to CSV\n",
    "# Include: actual_value, lr_predicted_value, rf_predicted_value\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"actual_value\": y_test.values,\n",
    "    \"lr_predicted_value\": lr_pred,\n",
    "    \"rf_predicted_value\": rf_pred,\n",
    "})\n",
    "\n",
    "pred_df.to_csv(\"output/q2_ml_predictions.csv\", index=False)\n",
    "print(f\"\\nSaved predictions to output/q2_ml_predictions.csv\")\n",
    "\n",
    "# TODO: Save model comparison to text file\n",
    "# Include both train and test metrics\n",
    "# Format: \"Linear Regression - Train R²: X.XXXX, Test R²: X.XXXX, Test RMSE: XX.XX\\nRandom Forest - Train R²: X.XXXX, Test R²: X.XXXX, Test RMSE: XX.XX\"\n",
    "\n",
    "with open(\"output/q2_model_comparison.txt\", \"w\") as f:\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7ae27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Question 3: Gradient Boosting with XGBoost\n",
    "\n",
    "**Note:** Question 3 introduces gradient boosting, an advanced machine learning technique that often achieves the best performance on tabular data. XGBoost builds models sequentially, with each new model learning from the mistakes of previous ones.\n",
    "\n",
    "**Objective:** Fit an XGBoost model and extract feature importance.\n",
    "\n",
    "### Part 3.1: Fit XGBoost Model\n",
    "\n",
    "Fit an XGBoost regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit an XGBRegressor model\n",
    "# Use: n_estimators=100, max_depth=3, learning_rate=0.15, random_state=42\n",
    "xgb_model = None  # Replace None with your code\n",
    "# Your code here\n",
    "\n",
    "# TODO: Make predictions on test set\n",
    "xgb_pred = None  # Replace None with your code\n",
    "\n",
    "# Calculate metrics\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "\n",
    "print(f\"XGBoost - R²: {xgb_r2:.4f}, RMSE: {xgb_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c8744",
   "metadata": {},
   "source": [
    "### Part 3.2: Extract and Compare Feature Importance\n",
    "\n",
    "Extract feature importance from XGBoost and compare it with Random Forest from Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract feature importance from XGBoost\n",
    "# Use: xgb_model.feature_importances_\n",
    "xgb_feature_importance = None  # Replace None with your code\n",
    "\n",
    "# Create DataFrame for XGBoost importance\n",
    "xgb_importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"xgb_importance\": xgb_feature_importance,\n",
    "}).sort_values(\"xgb_importance\", ascending=False)\n",
    "\n",
    "print(\"\\n=== XGBoost Feature Importance ===\")\n",
    "print(xgb_importance_df)\n",
    "\n",
    "# TODO: Compare with Random Forest feature importance\n",
    "# Create a comparison DataFrame with both models' feature importance\n",
    "# Sort by XGBoost importance for display\n",
    "\n",
    "importance_comparison = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"random_forest\": rf_feature_importance,\n",
    "    \"xgboost\": xgb_feature_importance,\n",
    "}).sort_values(\"xgboost\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance Comparison ===\")\n",
    "print(importance_comparison)\n",
    "\n",
    "# TODO: Save XGBoost feature importance to text file\n",
    "# Format: \"feature_name: X.XXXX\" (one per line, sorted by importance)\n",
    "\n",
    "with open(\"output/q3_feature_importance.txt\", \"w\") as f:\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3349430",
   "metadata": {},
   "source": [
    "### Part 3.3: Save Predictions\n",
    "\n",
    "Save XGBoost predictions to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save predictions to CSV\n",
    "# Include: actual_value, xgb_predicted_value\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"actual_value\": y_test.values,\n",
    "    \"xgb_predicted_value\": xgb_pred,\n",
    "})\n",
    "\n",
    "pred_df.to_csv(\"output/q3_xgboost_model.csv\", index=False)\n",
    "print(f\"\\nSaved predictions to output/q3_xgboost_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9bcb1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "Before submitting, verify you've created all required output files:\n",
    "\n",
    "- [ ] `output/q1_statistical_model.csv`\n",
    "- [ ] `output/q1_model_summary.txt`\n",
    "- [ ] `output/q2_ml_predictions.csv`\n",
    "- [ ] `output/q2_model_comparison.txt`\n",
    "- [ ] `output/q3_xgboost_model.csv`\n",
    "- [ ] `output/q3_feature_importance.txt`\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
