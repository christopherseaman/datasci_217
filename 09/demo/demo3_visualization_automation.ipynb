{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622f7fc2",
   "metadata": {},
   "source": [
    "# Demo 3: Time Series Visualization and Automation\n",
    "\n",
    "## Learning Objectives\n",
    "- Create effective time series visualizations\n",
    "- Perform seasonal decomposition\n",
    "- Set up automated analysis with cron jobs\n",
    "- Monitor time series performance\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set inline plotting for Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7c526",
   "metadata": {},
   "source": [
    "## Part 1: Time Series Visualization\n",
    "\n",
    "### Create Sample Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7038a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic time series data\n",
    "print(\"=== Creating Sample Time Series ===\")\n",
    "\n",
    "# Generate time series with trend, seasonality, and noise\n",
    "dates = pd.date_range('2020-01-01', periods=365*3, freq='D')\n",
    "n = len(dates)\n",
    "\n",
    "# Trend component\n",
    "trend = np.linspace(100, 150, n)\n",
    "\n",
    "# Seasonal component (annual cycle)\n",
    "seasonal = 10 * np.sin(2 * np.pi * np.arange(n) / 365.25)\n",
    "\n",
    "# Noise component\n",
    "noise = np.random.normal(0, 5, n)\n",
    "\n",
    "# Combine components\n",
    "values = trend + seasonal + noise\n",
    "ts = pd.Series(values, index=dates)\n",
    "ts.name = 'Time Series'\n",
    "\n",
    "print(f\"Time series shape: {ts.shape}\")\n",
    "print(f\"Date range: {ts.index.min()} to {ts.index.max()}\")\n",
    "print(f\"Value range: {ts.min():.2f} to {ts.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b362fed1",
   "metadata": {},
   "source": [
    "### Basic Time Series Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a46e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic time series plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Line plot\n",
    "axes[0, 0].plot(ts.index, ts.values, linewidth=1)\n",
    "axes[0, 0].set_title('Time Series Line Plot')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Rolling mean\n",
    "rolling_mean = ts.rolling(window=30).mean()\n",
    "axes[0, 1].plot(ts.index, ts.values, alpha=0.7, label='Original')\n",
    "axes[0, 1].plot(rolling_mean.index, rolling_mean.values, linewidth=2, label='30-day MA')\n",
    "axes[0, 1].set_title('Time Series with Rolling Mean')\n",
    "axes[0, 1].set_ylabel('Value')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram\n",
    "axes[1, 0].hist(ts.values, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Value Distribution')\n",
    "axes[1, 0].set_xlabel('Value')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot by month\n",
    "monthly_data = [ts[ts.index.month == i].values for i in range(1, 13)]\n",
    "axes[1, 1].boxplot(monthly_data, labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                                        'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "axes[1, 1].set_title('Monthly Distribution')\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Value')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5748dc30",
   "metadata": {},
   "source": [
    "### Advanced Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Multiple time series\n",
    "ts_ma5 = ts.rolling(window=5).mean()\n",
    "ts_ma20 = ts.rolling(window=20).mean()\n",
    "ts_ma50 = ts.rolling(window=50).mean()\n",
    "\n",
    "axes[0, 0].plot(ts.index, ts.values, alpha=0.7, label='Original')\n",
    "axes[0, 0].plot(ts_ma5.index, ts_ma5.values, label='5-day MA')\n",
    "axes[0, 0].plot(ts_ma20.index, ts_ma20.values, label='20-day MA')\n",
    "axes[0, 0].plot(ts_ma50.index, ts_ma50.values, label='50-day MA')\n",
    "axes[0, 0].set_title('Multiple Moving Averages')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Volatility analysis\n",
    "returns = ts.pct_change()\n",
    "volatility = returns.rolling(window=20).std()\n",
    "\n",
    "axes[0, 1].plot(ts.index, ts.values, alpha=0.7, label='Price')\n",
    "axes[0, 1].set_ylabel('Price', color='blue')\n",
    "axes[0, 1].tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "ax2 = axes[0, 1].twinx()\n",
    "ax2.plot(volatility.index, volatility.values, color='red', alpha=0.7, label='Volatility')\n",
    "ax2.set_ylabel('Volatility', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "axes[0, 1].set_title('Price and Volatility')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Seasonal analysis\n",
    "monthly_means = ts.groupby(ts.index.month).mean()\n",
    "axes[1, 0].plot(monthly_means.index, monthly_means.values, marker='o', linewidth=2)\n",
    "axes[1, 0].set_title('Seasonal Pattern (Monthly Means)')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average Value')\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation analysis\n",
    "ts_df = ts.to_frame()\n",
    "ts_df['lag_1'] = ts.shift(1)\n",
    "ts_df['lag_7'] = ts.shift(7)\n",
    "ts_df['lag_30'] = ts.shift(30)\n",
    "\n",
    "correlation_matrix = ts_df.corr()\n",
    "im = axes[1, 1].imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
    "axes[1, 1].set_title('Autocorrelation Matrix')\n",
    "axes[1, 1].set_xticks(range(len(correlation_matrix.columns)))\n",
    "axes[1, 1].set_yticks(range(len(correlation_matrix.index)))\n",
    "axes[1, 1].set_xticklabels(correlation_matrix.columns, rotation=45)\n",
    "axes[1, 1].set_yticklabels(correlation_matrix.index)\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar(im, ax=axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d2c0b",
   "metadata": {},
   "source": [
    "## Part 2: Seasonal Decomposition\n",
    "\n",
    "### Basic Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition\n",
    "print(\"=== Seasonal Decomposition ===\")\n",
    "\n",
    "# Use statsmodels for decomposition\n",
    "try:\n",
    "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "    \n",
    "    # Decompose time series\n",
    "    decomposition = seasonal_decompose(ts, model='additive', period=365)\n",
    "    \n",
    "    # Plot decomposition\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "    \n",
    "    decomposition.observed.plot(ax=axes[0], title='Original')\n",
    "    decomposition.trend.plot(ax=axes[1], title='Trend')\n",
    "    decomposition.seasonal.plot(ax=axes[2], title='Seasonal')\n",
    "    decomposition.resid.plot(ax=axes[3], title='Residual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print decomposition statistics\n",
    "    print(\"Decomposition Statistics:\")\n",
    "    print(f\"Trend range: {decomposition.trend.min():.2f} to {decomposition.trend.max():.2f}\")\n",
    "    print(f\"Seasonal range: {decomposition.seasonal.min():.2f} to {decomposition.seasonal.max():.2f}\")\n",
    "    print(f\"Residual range: {decomposition.resid.min():.2f} to {decomposition.resid.max():.2f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"statsmodels not available. Install with: pip install statsmodels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81ad4c",
   "metadata": {},
   "source": [
    "### Manual Seasonal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d555b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual seasonal analysis\n",
    "print(\"=== Manual Seasonal Analysis ===\")\n",
    "\n",
    "# Calculate seasonal components\n",
    "ts_df = ts.to_frame()\n",
    "ts_df['year'] = ts_df.index.year\n",
    "ts_df['month'] = ts_df.index.month\n",
    "ts_df['day_of_year'] = ts_df.index.dayofyear\n",
    "\n",
    "# Monthly seasonal pattern\n",
    "monthly_pattern = ts_df.groupby('month')['Time Series'].mean()\n",
    "print(\"Monthly seasonal pattern:\")\n",
    "print(monthly_pattern)\n",
    "\n",
    "# Plot seasonal patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Monthly pattern\n",
    "monthly_pattern.plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Monthly Seasonal Pattern')\n",
    "axes[0, 0].set_xlabel('Month')\n",
    "axes[0, 0].set_ylabel('Average Value')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Day of year pattern\n",
    "daily_pattern = ts_df.groupby('day_of_year')['Time Series'].mean()\n",
    "axes[0, 1].plot(daily_pattern.index, daily_pattern.values)\n",
    "axes[0, 1].set_title('Daily Seasonal Pattern')\n",
    "axes[0, 1].set_xlabel('Day of Year')\n",
    "axes[0, 1].set_ylabel('Average Value')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Yearly comparison\n",
    "yearly_data = ts_df.groupby('year')['Time Series'].mean()\n",
    "axes[1, 0].plot(yearly_data.index, yearly_data.values, marker='o')\n",
    "axes[1, 0].set_title('Yearly Averages')\n",
    "axes[1, 0].set_xlabel('Year')\n",
    "axes[1, 0].set_ylabel('Average Value')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Heatmap of seasonal patterns\n",
    "pivot_data = ts_df.pivot_table(values='Time Series', index='month', columns='year', aggfunc='mean')\n",
    "sns.heatmap(pivot_data, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Seasonal Heatmap (Month vs Year)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e15719",
   "metadata": {},
   "source": [
    "## Part 3: Automation with Cron Jobs\n",
    "\n",
    "### Cron Job Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20159e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate cron job setup\n",
    "print(\"=== Cron Job Setup ===\")\n",
    "print(\"In a real scenario, you would:\")\n",
    "print(\"1. Create a Python script for time series analysis\")\n",
    "print(\"2. Set up cron job to run the script automatically\")\n",
    "print(\"3. Configure logging and error handling\")\n",
    "print(\"4. Set up monitoring and alerts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc96d80",
   "metadata": {},
   "source": [
    "### Time Series Analysis Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series analysis script\n",
    "def create_analysis_script():\n",
    "    \"\"\"Create a time series analysis script for cron job\"\"\"\n",
    "    \n",
    "    script_content = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Time series analysis script for cron job\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename='/path/to/logs/time_series_analysis.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def run_time_series_analysis():\n",
    "    \"\"\"Run daily time series analysis\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv('/path/to/data/time_series_data.csv')\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.set_index('date', inplace=True)\n",
    "        \n",
    "        # Perform analysis\n",
    "        daily_stats = df.resample('D').agg({\n",
    "            'value': ['mean', 'std', 'min', 'max'],\n",
    "            'volume': 'sum'\n",
    "        })\n",
    "        \n",
    "        # Calculate moving averages\n",
    "        df['ma_7'] = df['value'].rolling(window=7).mean()\n",
    "        df['ma_30'] = df['value'].rolling(window=30).mean()\n",
    "        \n",
    "        # Detect anomalies\n",
    "        df['anomaly'] = abs(df['value'] - df['ma_7']) > 2 * df['value'].rolling(window=30).std()\n",
    "        \n",
    "        # Save results\n",
    "        daily_stats.to_csv('/path/to/results/daily_stats.csv')\n",
    "        df.to_csv('/path/to/results/analysis_results.csv')\n",
    "        \n",
    "        # Log completion\n",
    "        logging.info(\"Time series analysis completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in time series analysis: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_time_series_analysis()\n",
    "'''\n",
    "    \n",
    "    return script_content\n",
    "\n",
    "# Display the script\n",
    "print(\"=== Time Series Analysis Script ===\")\n",
    "script = create_analysis_script()\n",
    "print(script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8836c25f",
   "metadata": {},
   "source": [
    "### Cron Job Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cron job configuration\n",
    "def create_cron_config():\n",
    "    \"\"\"Create cron job configuration\"\"\"\n",
    "    \n",
    "    cron_config = '''\n",
    "# Time series analysis cron jobs\n",
    "# Run every day at 2 AM\n",
    "0 2 * * * /path/to/scripts/time_series_analysis.sh\n",
    "\n",
    "# Run every Monday at 9 AM\n",
    "0 9 * * 1 /path/to/scripts/weekly_analysis.sh\n",
    "\n",
    "# Run every 15 minutes during business hours\n",
    "*/15 9-17 * * 1-5 /path/to/scripts/realtime_analysis.sh\n",
    "\n",
    "# Run at specific times\n",
    "0 9,17 * * * /path/to/scripts/business_hours_analysis.sh\n",
    "'''\n",
    "    \n",
    "    return cron_config\n",
    "\n",
    "print(\"=== Cron Job Configuration ===\")\n",
    "config = create_cron_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b6c02",
   "metadata": {},
   "source": [
    "## Part 4: Performance Monitoring\n",
    "\n",
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4beccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance monitoring\n",
    "def monitor_performance():\n",
    "    \"\"\"Monitor time series analysis performance\"\"\"\n",
    "    \n",
    "    print(\"=== Performance Monitoring ===\")\n",
    "    \n",
    "    # Simulate performance metrics\n",
    "    metrics = {\n",
    "        'data_size': '1M records',\n",
    "        'processing_time': '2.5 seconds',\n",
    "        'memory_usage': '512 MB',\n",
    "        'cpu_usage': '45%',\n",
    "        'disk_usage': '2.1 GB',\n",
    "        'error_rate': '0.1%'\n",
    "    }\n",
    "    \n",
    "    print(\"Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    \n",
    "    # Create performance report\n",
    "    report = f\"\"\"\n",
    "Time Series Analysis Performance Report\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "Data Processing:\n",
    "- Data size: {metrics['data_size']}\n",
    "- Processing time: {metrics['processing_time']}\n",
    "- Memory usage: {metrics['memory_usage']}\n",
    "- CPU usage: {metrics['cpu_usage']}\n",
    "\n",
    "Storage:\n",
    "- Disk usage: {metrics['disk_usage']}\n",
    "\n",
    "Quality:\n",
    "- Error rate: {metrics['error_rate']}\n",
    "\n",
    "Status: All systems operational\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate performance report\n",
    "performance_report = monitor_performance()\n",
    "print(performance_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59151d6",
   "metadata": {},
   "source": [
    "### Automated Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e062355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated monitoring system\n",
    "def create_monitoring_system():\n",
    "    \"\"\"Create automated monitoring system\"\"\"\n",
    "    \n",
    "    monitoring_script = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Automated monitoring system for time series analysis\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "def check_data_quality(df):\n",
    "    \"\"\"Check data quality metrics\"\"\"\n",
    "    quality_metrics = {\n",
    "        'missing_values': df.isnull().sum().sum(),\n",
    "        'duplicate_rows': df.duplicated().sum(),\n",
    "        'data_range': (df.max() - df.min()).mean(),\n",
    "        'outlier_count': len(df[(df - df.mean()).abs() > 3 * df.std()])\n",
    "    }\n",
    "    return quality_metrics\n",
    "\n",
    "def check_performance_metrics():\n",
    "    \"\"\"Check performance metrics\"\"\"\n",
    "    # Simulate performance monitoring\n",
    "    return {\n",
    "        'processing_time': 2.5,\n",
    "        'memory_usage': 512,\n",
    "        'cpu_usage': 45,\n",
    "        'error_count': 0\n",
    "    }\n",
    "\n",
    "def send_alert(message):\n",
    "    \"\"\"Send alert notification\"\"\"\n",
    "    # Simulate alert sending\n",
    "    print(f\"ALERT: {message}\")\n",
    "    logging.warning(f\"Alert sent: {message}\")\n",
    "\n",
    "def run_monitoring():\n",
    "    \"\"\"Run automated monitoring\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv('/path/to/data/time_series_data.csv')\n",
    "        \n",
    "        # Check data quality\n",
    "        quality = check_data_quality(df)\n",
    "        if quality['missing_values'] > 100:\n",
    "            send_alert(\"High number of missing values detected\")\n",
    "        \n",
    "        # Check performance\n",
    "        performance = check_performance_metrics()\n",
    "        if performance['processing_time'] > 10:\n",
    "            send_alert(\"Processing time exceeded threshold\")\n",
    "        \n",
    "        if performance['memory_usage'] > 1000:\n",
    "            send_alert(\"Memory usage exceeded threshold\")\n",
    "        \n",
    "        # Log monitoring results\n",
    "        logging.info(f\"Monitoring completed - Quality: {quality}, Performance: {performance}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Monitoring error: {e}\")\n",
    "        send_alert(f\"Monitoring system error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_monitoring()\n",
    "'''\n",
    "    \n",
    "    return monitoring_script\n",
    "\n",
    "print(\"=== Automated Monitoring System ===\")\n",
    "monitoring_script = create_monitoring_system()\n",
    "print(monitoring_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a32ce01",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Time Series Visualization**: Create effective plots for trend, seasonality, and patterns\n",
    "2. **Seasonal Decomposition**: Separate trend, seasonal, and residual components\n",
    "3. **Automation**: Set up cron jobs for automated time series analysis\n",
    "4. **Monitoring**: Track performance and data quality metrics\n",
    "5. **Real-world Application**: Apply techniques to production time series systems\n",
    "6. **Best Practices**: Use logging, error handling, and alerting for robust systems\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Practice with your own time series data\n",
    "- Set up automated analysis pipelines\n",
    "- Learn about time series forecasting\n",
    "- Explore advanced time series techniques"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
