{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "838005bc",
   "metadata": {},
   "source": [
    "# Notebook 4: Modeling & Results\n",
    "\n",
    "**Phases 8-9:** Modeling, Results & Insights\n",
    "\n",
    "**Dataset:** NYC Taxi Trip Dataset (continuing from Notebook 3)\n",
    "\n",
    "**Focus:** Building predictive models, evaluating performance, interpreting results, and communicating insights.\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 8: Modeling\n",
    "\n",
    "### Learning Objectives\n",
    "- Train multiple model types\n",
    "- Evaluate model performance\n",
    "- Compare models\n",
    "- Interpret model results\n",
    "- Identify overfitting\n",
    "\n",
    "### Step 1: Load Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb1ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Modeling libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Load prepared data from Notebook 3\n",
    "X_train = pd.read_csv('../output/03_X_train.csv')\n",
    "X_test = pd.read_csv('../output/03_X_test.csv')\n",
    "y_train = pd.read_csv('../output/03_y_train.csv').squeeze()  # Convert to Series\n",
    "y_test = pd.read_csv('../output/03_y_test.csv').squeeze()\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Features: {list(X_train.columns[:5])}... ({len(X_train.columns)} total)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a907be",
   "metadata": {},
   "source": [
    "### Step 2: Baseline Model - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d137a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear regression model\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL 1: Linear Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lr = lr_model.predict(X_train)\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_rmse_lr = np.sqrt(mean_squared_error(y_train, y_train_pred_lr))\n",
    "test_rmse_lr = np.sqrt(mean_squared_error(y_test, y_test_pred_lr))\n",
    "train_mae_lr = mean_absolute_error(y_train, y_train_pred_lr)\n",
    "test_mae_lr = mean_absolute_error(y_test, y_test_pred_lr)\n",
    "train_r2_lr = r2_score(y_train, y_train_pred_lr)\n",
    "test_r2_lr = r2_score(y_test, y_test_pred_lr)\n",
    "\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: ${train_rmse_lr:.2f}\")\n",
    "print(f\"  MAE: ${train_mae_lr:.2f}\")\n",
    "print(f\"  R¬≤: {train_r2_lr:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  RMSE: ${test_rmse_lr:.2f}\")\n",
    "print(f\"  MAE: ${test_mae_lr:.2f}\")\n",
    "print(f\"  R¬≤: {test_r2_lr:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_lr = train_r2_lr - test_r2_lr\n",
    "print(f\"\\nOverfitting (R¬≤ difference): {overfit_lr:.4f}\")\n",
    "if overfit_lr > 0.1:\n",
    "    print(\"  ‚ö†Ô∏è  Warning: Significant overfitting detected\")\n",
    "else:\n",
    "    print(\"  ‚úì Model generalizes well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bf05f",
   "metadata": {},
   "source": [
    "### Step 3: Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85146786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 2: Random Forest\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, y_train_pred_rf))\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))\n",
    "train_mae_rf = mean_absolute_error(y_train, y_train_pred_rf)\n",
    "test_mae_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
    "train_r2_rf = r2_score(y_train, y_train_pred_rf)\n",
    "test_r2_rf = r2_score(y_test, y_test_pred_rf)\n",
    "\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: ${train_rmse_rf:.2f}\")\n",
    "print(f\"  MAE: ${train_mae_rf:.2f}\")\n",
    "print(f\"  R¬≤: {train_r2_rf:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  RMSE: ${test_rmse_rf:.2f}\")\n",
    "print(f\"  MAE: ${test_mae_rf:.2f}\")\n",
    "print(f\"  R¬≤: {test_r2_rf:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_rf = train_r2_rf - test_r2_rf\n",
    "print(f\"\\nOverfitting (R¬≤ difference): {overfit_rf:.4f}\")\n",
    "if overfit_rf > 0.1:\n",
    "    print(\"  ‚ö†Ô∏è  Warning: Significant overfitting detected\")\n",
    "else:\n",
    "    print(\"  ‚úì Model generalizes well\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "display(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cc605",
   "metadata": {},
   "source": [
    "### Step 4: XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada24e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 3: XGBoost\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_rmse_xgb = np.sqrt(mean_squared_error(y_train, y_train_pred_xgb))\n",
    "test_rmse_xgb = np.sqrt(mean_squared_error(y_test, y_test_pred_xgb))\n",
    "train_mae_xgb = mean_absolute_error(y_train, y_train_pred_xgb)\n",
    "test_mae_xgb = mean_absolute_error(y_test, y_test_pred_xgb)\n",
    "train_r2_xgb = r2_score(y_train, y_train_pred_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "print(f\"\\nTraining Performance:\")\n",
    "print(f\"  RMSE: ${train_rmse_xgb:.2f}\")\n",
    "print(f\"  MAE: ${train_mae_xgb:.2f}\")\n",
    "print(f\"  R¬≤: {train_r2_xgb:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  RMSE: ${test_rmse_xgb:.2f}\")\n",
    "print(f\"  MAE: ${test_mae_xgb:.2f}\")\n",
    "print(f\"  R¬≤: {test_r2_xgb:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_xgb = train_r2_xgb - test_r2_xgb\n",
    "print(f\"\\nOverfitting (R¬≤ difference): {overfit_xgb:.4f}\")\n",
    "if overfit_xgb > 0.1:\n",
    "    print(\"  ‚ö†Ô∏è  Warning: Significant overfitting detected\")\n",
    "else:\n",
    "    print(\"  ‚úì Model generalizes well\")\n",
    "\n",
    "# Feature importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Features:\")\n",
    "display(xgb_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ada92",
   "metadata": {},
   "source": [
    "### Step 5: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Train RMSE': [train_rmse_lr, train_rmse_rf, train_rmse_xgb],\n",
    "    'Test RMSE': [test_rmse_lr, test_rmse_rf, test_rmse_xgb],\n",
    "    'Train R¬≤': [train_r2_lr, train_r2_rf, train_r2_xgb],\n",
    "    'Test R¬≤': [test_r2_lr, test_r2_rf, test_r2_xgb],\n",
    "    'Overfitting': [overfit_lr, overfit_rf, overfit_xgb]\n",
    "})\n",
    "\n",
    "comparison = comparison.round(4)\n",
    "comparison['RMSE_diff'] = comparison['Train RMSE'] - comparison['Test RMSE']\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "display(comparison)\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# RMSE comparison\n",
    "x_pos = np.arange(len(comparison))\n",
    "width = 0.35\n",
    "axes[0].bar(x_pos - width/2, comparison['Train RMSE'], width, label='Train', alpha=0.7)\n",
    "axes[0].bar(x_pos + width/2, comparison['Test RMSE'], width, label='Test', alpha=0.7)\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].set_ylabel('RMSE ($)')\n",
    "axes[0].set_title('RMSE: Train vs Test')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(comparison['Model'], rotation=45, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# R¬≤ comparison\n",
    "axes[1].bar(x_pos - width/2, comparison['Train R¬≤'], width, label='Train', alpha=0.7)\n",
    "axes[1].bar(x_pos + width/2, comparison['Test R¬≤'], width, label='Test', alpha=0.7)\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].set_ylabel('R¬≤ Score')\n",
    "axes[1].set_title('R¬≤: Train vs Test')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(comparison['Model'], rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select best model (lowest test RMSE)\n",
    "best_model_idx = comparison['Test RMSE'].idxmin()\n",
    "best_model_name = comparison.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} (Test RMSE: ${comparison.loc[best_model_idx, 'Test RMSE']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8deb0",
   "metadata": {},
   "source": [
    "### Step 6: Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204dcdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best model for visualization (XGBoost typically performs best)\n",
    "y_test_pred_best = y_test_pred_xgb\n",
    "\n",
    "# Scatter plot: Actual vs Predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Model Predictions: Actual vs Predicted', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_test_pred_best, alpha=0.3, s=10)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Fare ($)')\n",
    "axes[0].set_ylabel('Predicted Fare ($)')\n",
    "axes[0].set_title('Actual vs Predicted Fare')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - y_test_pred_best\n",
    "axes[1].scatter(y_test_pred_best, residuals, alpha=0.3, s=10)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted Fare ($)')\n",
    "axes[1].set_ylabel('Residuals ($)')\n",
    "axes[1].set_title('Residuals Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals statistics\n",
    "print(f\"\\nResiduals Statistics:\")\n",
    "print(f\"  Mean: ${residuals.mean():.2f}\")\n",
    "print(f\"  Std: ${residuals.std():.2f}\")\n",
    "print(f\"  Min: ${residuals.min():.2f}\")\n",
    "print(f\"  Max: ${residuals.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f8fa40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 9: Results & Insights\n",
    "\n",
    "### Learning Objectives\n",
    "- Summarize key findings\n",
    "- Create final visualizations\n",
    "- Document results\n",
    "- Communicate insights effectively\n",
    "\n",
    "### Step 1: Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9095bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. DATA OVERVIEW:\")\n",
    "print(f\"   - Total trips analyzed: {len(X_train) + len(X_test):,}\")\n",
    "print(f\"   - Training period: {pd.read_csv('../output/03_X_train.csv').shape[0]:,} trips\")\n",
    "print(f\"   - Test period: {len(X_test):,} trips\")\n",
    "print(f\"   - Features used: {len(X_train.columns)}\")\n",
    "\n",
    "print(\"\\n2. MODEL PERFORMANCE:\")\n",
    "print(f\"   - Best model: {best_model_name}\")\n",
    "print(f\"   - Test RMSE: ${comparison.loc[best_model_idx, 'Test RMSE']:.2f}\")\n",
    "print(f\"   - Test R¬≤: {comparison.loc[best_model_idx, 'Test R¬≤']:.4f}\")\n",
    "print(f\"   - Average prediction error: ${comparison.loc[best_model_idx, 'Test RMSE']:.2f}\")\n",
    "\n",
    "print(\"\\n3. KEY INSIGHTS:\")\n",
    "# Get top features from best model\n",
    "if best_model_name == 'XGBoost':\n",
    "    top_features = xgb_importance.head(5)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    top_features = feature_importance.head(5)\n",
    "else:\n",
    "    top_features = pd.DataFrame({'feature': ['trip_distance', 'trip_duration'], 'importance': [0.5, 0.3]})\n",
    "\n",
    "print(\"   Most important features for fare prediction:\")\n",
    "for idx, row in top_features.iterrows():\n",
    "    print(f\"   - {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "print(\"\\n4. MODEL INTERPRETATION:\")\n",
    "print(f\"   - The model explains {comparison.loc[best_model_idx, 'Test R¬≤']*100:.1f}% of fare variance\")\n",
    "print(f\"   - Predictions are within ${comparison.loc[best_model_idx, 'Test RMSE']:.2f} on average\")\n",
    "if comparison.loc[best_model_idx, 'Overfitting'] < 0.05:\n",
    "    print(\"   - Model generalizes well to new data\")\n",
    "else:\n",
    "    print(\"   - Some overfitting detected - model may need regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba5653",
   "metadata": {},
   "source": [
    "### Step 2: Final Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ff38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "fig.suptitle('Final Results: NYC Taxi Fare Prediction Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Model comparison\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "x_pos = np.arange(len(comparison))\n",
    "ax1.bar(x_pos, comparison['Test R¬≤'], alpha=0.7, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(comparison['Model'], rotation=45, ha='right')\n",
    "ax1.set_ylabel('Test R¬≤ Score')\n",
    "ax1.set_title('Model Performance (Test R¬≤)')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 2. Feature importance (top 10)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "if best_model_name == 'XGBoost':\n",
    "    top_10 = xgb_importance.head(10)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    top_10 = feature_importance.head(10)\n",
    "else:\n",
    "    top_10 = pd.DataFrame({'feature': X_train.columns[:10], 'importance': [0.1]*10})\n",
    "ax2.barh(range(len(top_10)), top_10['importance'], alpha=0.7)\n",
    "ax2.set_yticks(range(len(top_10)))\n",
    "ax2.set_yticklabels(top_10['feature'])\n",
    "ax2.set_xlabel('Importance')\n",
    "ax2.set_title('Top 10 Feature Importance')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 3. Actual vs Predicted\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "ax3.scatter(y_test, y_test_pred_best, alpha=0.3, s=10)\n",
    "ax3.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "ax3.set_xlabel('Actual Fare ($)')\n",
    "ax3.set_ylabel('Predicted Fare ($)')\n",
    "ax3.set_title('Prediction Accuracy: Actual vs Predicted')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Residuals distribution\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "ax4.hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "ax4.axvline(residuals.mean(), color='r', linestyle='--', linewidth=2, label=f'Mean: ${residuals.mean():.2f}')\n",
    "ax4.set_xlabel('Residuals ($)')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Residuals Distribution')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 5. Error by fare range\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "fare_bins = pd.cut(y_test, bins=5)\n",
    "error_by_fare = pd.DataFrame({\n",
    "    'fare_range': fare_bins,\n",
    "    'abs_error': np.abs(residuals)\n",
    "}).groupby('fare_range')['abs_error'].mean()\n",
    "ax5.bar(range(len(error_by_fare)), error_by_fare.values, alpha=0.7)\n",
    "ax5.set_xticks(range(len(error_by_fare)))\n",
    "ax5.set_xticklabels([str(x) for x in error_by_fare.index], rotation=45, ha='right')\n",
    "ax5.set_ylabel('Mean Absolute Error ($)')\n",
    "ax5.set_title('Prediction Error by Fare Range')\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../output/04_final_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Final visualization saved to: ../output/04_final_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a8600",
   "metadata": {},
   "source": [
    "### Step 3: Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a316d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions and results\n",
    "results_df = pd.DataFrame({\n",
    "    'actual_fare': y_test.values,\n",
    "    'predicted_fare': y_test_pred_best,\n",
    "    'residual': residuals.values,\n",
    "    'abs_error': np.abs(residuals.values)\n",
    "})\n",
    "\n",
    "results_df.to_csv('../output/04_model_predictions.csv', index=False)\n",
    "\n",
    "# Save model comparison\n",
    "comparison.to_csv('../output/04_model_comparison.csv', index=False)\n",
    "\n",
    "# Save feature importance\n",
    "if best_model_name == 'XGBoost':\n",
    "    xgb_importance.to_csv('../output/04_feature_importance.csv', index=False)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    feature_importance.to_csv('../output/04_feature_importance.csv', index=False)\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(\"  - Model predictions: ../output/04_model_predictions.csv\")\n",
    "print(\"  - Model comparison: ../output/04_model_comparison.csv\")\n",
    "print(\"  - Feature importance: ../output/04_feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f8668",
   "metadata": {},
   "source": [
    "### Step 4: Project Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae206e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "This complete data science project demonstrated:\n",
    "\n",
    "1. DATA CLEANING & EXPLORATION\n",
    "   - Handled missing values and outliers\n",
    "   - Explored distributions and relationships\n",
    "   - Identified data quality issues\n",
    "\n",
    "2. DATA WRANGLING & FEATURE ENGINEERING\n",
    "   - Merged multiple data sources\n",
    "   - Extracted temporal features\n",
    "   - Created derived variables\n",
    "   - Performed aggregations\n",
    "\n",
    "3. PATTERN ANALYSIS\n",
    "   - Identified trends and seasonality\n",
    "   - Analyzed correlations\n",
    "   - Created advanced visualizations\n",
    "\n",
    "4. MODELING\n",
    "   - Trained multiple model types\n",
    "   - Evaluated performance\n",
    "   - Selected best model\n",
    "   - Interpreted results\n",
    "\n",
    "5. RESULTS COMMUNICATION\n",
    "   - Summarized key findings\n",
    "   - Created final visualizations\n",
    "   - Documented insights\n",
    "\n",
    "KEY TAKEAWAYS:\n",
    "- Time series data requires temporal train/test splits\n",
    "- Feature engineering significantly improves model performance\n",
    "- Multiple models should be compared\n",
    "- Visualization is essential for understanding and communication\n",
    "- Proper workflow ensures reproducible and reliable results\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PROJECT COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6901b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ‚úÖ **Trained multiple models** (Linear Regression, Random Forest, XGBoost)\n",
    "2. ‚úÖ **Evaluated model performance** using multiple metrics\n",
    "3. ‚úÖ **Compared models** and selected the best\n",
    "4. ‚úÖ **Analyzed feature importance** to understand drivers\n",
    "5. ‚úÖ **Visualized predictions** and residuals\n",
    "6. ‚úÖ **Summarized key findings** and insights\n",
    "7. ‚úÖ **Created final visualizations** for communication\n",
    "8. ‚úÖ **Documented results** for reproducibility\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Multiple models should be tried and compared\n",
    "- Test performance is the true measure of model quality\n",
    "- Feature importance helps interpret model behavior\n",
    "- Visualizations are essential for understanding results\n",
    "- Proper documentation enables reproducibility\n",
    "\n",
    "**Congratulations!** You've completed a full data science project from raw data to insights! üéâ\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
