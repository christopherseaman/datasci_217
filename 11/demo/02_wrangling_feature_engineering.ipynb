{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a3da7d",
   "metadata": {},
   "source": [
    "# Notebook 2: Wrangling & Feature Engineering\n",
    "\n",
    "**Phases 4-5:** Data Wrangling & Transformation, Feature Engineering & Aggregation\n",
    "\n",
    "**Dataset:** NYC Taxi Trip Dataset (continuing from Notebook 1)\n",
    "\n",
    "**Focus:** Transforming and enriching data - merging datasets, working with datetime data, reshaping, and creating features for modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## Phase 4: Data Wrangling & Transformation\n",
    "\n",
    "### Learning Objectives\n",
    "- Merge and join multiple datasets\n",
    "- Handle datetime columns and set datetime index\n",
    "- Extract time-based features\n",
    "- Reshape data for analysis\n",
    "- Work with indexes\n",
    "\n",
    "### Step 1: Load Cleaned Data from Previous Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Load cleaned data from Notebook 1\n",
    "df = pd.read_csv('../output/01_cleaned_taxi_data.csv')\n",
    "print(f\"Loaded {len(df):,} cleaned taxi trips\")\n",
    "print(f\"Date range: {df['pickup_datetime'].min()} to {df['pickup_datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9823e43",
   "metadata": {},
   "source": [
    "### Step 2: Convert to Datetime and Set Datetime Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'])\n",
    "\n",
    "# Recalculate trip_duration if needed\n",
    "df['trip_duration'] = (df['dropoff_datetime'] - df['pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "# Set pickup_datetime as index for datetime-based operations\n",
    "df_ts = df.set_index('pickup_datetime').sort_index()\n",
    "\n",
    "print(f\"Datetime index set. Shape: {df_ts.shape}\")\n",
    "print(f\"Index range: {df_ts.index.min()} to {df_ts.index.max()}\")\n",
    "display(df_ts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20301a",
   "metadata": {},
   "source": [
    "### Step 3: Extract Time-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract various time-based features from the datetime index\n",
    "df_ts['hour'] = df_ts.index.hour\n",
    "df_ts['day_of_week'] = df_ts.index.dayofweek  # 0=Monday, 6=Sunday\n",
    "df_ts['day_name'] = df_ts.index.day_name()\n",
    "df_ts['month'] = df_ts.index.month\n",
    "df_ts['month_name'] = df_ts.index.month_name()\n",
    "df_ts['year'] = df_ts.index.year\n",
    "df_ts['is_weekend'] = df_ts['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Create time-of-day categories\n",
    "def get_time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df_ts['time_of_day'] = df_ts['hour'].apply(get_time_of_day)\n",
    "\n",
    "print(\"Time-based features extracted:\")\n",
    "print(df_ts[['hour', 'day_of_week', 'day_name', 'month', 'is_weekend', 'time_of_day']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74496d",
   "metadata": {},
   "source": [
    "### Step 4: Merge with Additional Data (Zone Lookup Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bdf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, you'd load a real zone lookup table\n",
    "# For this demo, we'll create a simplified zone lookup based on coordinates\n",
    "\n",
    "# Create zone lookup table (simplified - in practice this would be a real NYC zone file)\n",
    "zone_lookup = pd.DataFrame({\n",
    "    'zone_id': range(1, 21),\n",
    "    'zone_name': [f'Zone_{i}' for i in range(1, 21)],\n",
    "    'borough': np.random.choice(['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'], 20)\n",
    "})\n",
    "\n",
    "# Create pickup and dropoff zones based on coordinates (simplified)\n",
    "# In practice, you'd use actual zone boundaries\n",
    "np.random.seed(42)\n",
    "df_ts['pickup_zone_id'] = np.random.choice(zone_lookup['zone_id'], len(df_ts))\n",
    "df_ts['dropoff_zone_id'] = np.random.choice(zone_lookup['zone_id'], len(df_ts))\n",
    "\n",
    "# Merge pickup zone information using LEFT JOIN\n",
    "# LEFT JOIN keeps all rows from left DataFrame (df_ts), adds matching data from right (zone_lookup)\n",
    "# This is the most common join type - we want all trips, even if zone info is missing\n",
    "# IMPORTANT: Reset index before merge, then set it back to preserve DatetimeIndex\n",
    "df_ts_reset = df_ts.reset_index()\n",
    "df_ts_reset = df_ts_reset.merge(\n",
    "    zone_lookup.rename(columns={'zone_id': 'pickup_zone_id', 'zone_name': 'pickup_zone_name', 'borough': 'pickup_borough'}),\n",
    "    on='pickup_zone_id',\n",
    "    how='left'  # LEFT JOIN: keep all trips, add zone info where available\n",
    ")\n",
    "\n",
    "# Merge dropoff zone information\n",
    "df_ts_reset = df_ts_reset.merge(\n",
    "    zone_lookup.rename(columns={'zone_id': 'dropoff_zone_id', 'zone_name': 'dropoff_zone_name', 'borough': 'dropoff_borough'}),\n",
    "    on='dropoff_zone_id',\n",
    "    how='left'  # LEFT JOIN: keep all trips\n",
    ")\n",
    "\n",
    "# Set datetime index back\n",
    "df_ts = df_ts_reset.set_index('pickup_datetime').sort_index()\n",
    "\n",
    "print(\"Zone information merged:\")\n",
    "print(f\"Columns: {df_ts.shape[1]}\")\n",
    "display(df_ts[['pickup_zone_name', 'pickup_borough', 'dropoff_zone_name', 'dropoff_borough']].head())\n",
    "\n",
    "# Demonstrate other join types (for educational purposes)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"JOIN TYPE EXAMPLES (Educational)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create example DataFrames to demonstrate join types\n",
    "left_df = pd.DataFrame({'key': [1, 2, 3, 4], 'left_value': ['A', 'B', 'C', 'D']})\n",
    "right_df = pd.DataFrame({'key': [2, 3, 4, 5], 'right_value': ['X', 'Y', 'Z', 'W']})\n",
    "\n",
    "print(\"Left DataFrame:\")\n",
    "display(left_df)\n",
    "print(\"\\nRight DataFrame:\")\n",
    "display(right_df)\n",
    "\n",
    "# INNER JOIN: Only rows with matching keys in both DataFrames\n",
    "inner_result = pd.merge(left_df, right_df, on='key', how='inner')\n",
    "print(\"\\nINNER JOIN (only matching keys):\")\n",
    "display(inner_result)\n",
    "\n",
    "# LEFT JOIN: All rows from left, matching from right\n",
    "left_result = pd.merge(left_df, right_df, on='key', how='left')\n",
    "print(\"\\nLEFT JOIN (all from left, matching from right):\")\n",
    "display(left_result)\n",
    "\n",
    "# RIGHT JOIN: All rows from right, matching from left\n",
    "right_result = pd.merge(left_df, right_df, on='key', how='right')\n",
    "print(\"\\nRIGHT JOIN (all from right, matching from left):\")\n",
    "display(right_result)\n",
    "\n",
    "# OUTER JOIN: All rows from both DataFrames\n",
    "outer_result = pd.merge(left_df, right_df, on='key', how='outer')\n",
    "print(\"\\nOUTER JOIN (all rows from both):\")\n",
    "display(outer_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b11e2",
   "metadata": {},
   "source": [
    "### Step 5: Reshape Data - Pivot Table Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5da045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table: Average fare by day of week and time of day\n",
    "pivot_fare = df_ts.pivot_table(\n",
    "    values='fare_amount',\n",
    "    index='day_name',\n",
    "    columns='time_of_day',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(\"Average Fare by Day of Week and Time of Day:\")\n",
    "display(pivot_fare.round(2))\n",
    "\n",
    "# Visualize the pivot table\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot_fare, annot=True, fmt='.1f', cmap='YlOrRd', cbar_kws={'label': 'Average Fare ($)'})\n",
    "plt.title('Average Fare Amount by Day and Time of Day', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Day of Week')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60461b4f",
   "metadata": {},
   "source": [
    "### Step 6: Reshape Data - Melt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert wide format to long format\n",
    "# Let's create a summary by hour with multiple metrics\n",
    "\n",
    "hourly_summary = df_ts.groupby('hour').agg({\n",
    "    'fare_amount': 'mean',\n",
    "    'trip_distance': 'mean',\n",
    "    'trip_duration': 'mean',\n",
    "    'passenger_count': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Hourly Summary (Wide Format):\")\n",
    "display(hourly_summary.head())\n",
    "\n",
    "# Melt to long format\n",
    "hourly_long = hourly_summary.melt(\n",
    "    id_vars='hour',\n",
    "    value_vars=['fare_amount', 'trip_distance', 'trip_duration', 'passenger_count'],\n",
    "    var_name='metric',\n",
    "    value_name='value'\n",
    ")\n",
    "\n",
    "print(\"\\nHourly Summary (Long Format):\")\n",
    "display(hourly_long.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772be754",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 5: Feature Engineering & Aggregation\n",
    "\n",
    "### Learning Objectives\n",
    "- Create derived features\n",
    "- Perform groupby aggregations\n",
    "- Calculate rolling window statistics\n",
    "- Create time-based features\n",
    "- Aggregate by multiple dimensions\n",
    "\n",
    "### Step 1: Create Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b00426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed (miles per hour) - derived from distance and duration\n",
    "df_ts['speed_mph'] = df_ts['trip_distance'] / (df_ts['trip_duration'] / 60)  # Convert minutes to hours\n",
    "df_ts['speed_mph'] = df_ts['speed_mph'].replace([np.inf, -np.inf], np.nan)  # Handle division by zero\n",
    "df_ts['speed_mph'] = df_ts['speed_mph'].clip(upper=60)  # Cap at 60 mph (reasonable for NYC)\n",
    "\n",
    "# Fare per mile\n",
    "df_ts['fare_per_mile'] = df_ts['fare_amount'] / df_ts['trip_distance']\n",
    "df_ts['fare_per_mile'] = df_ts['fare_per_mile'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Tip percentage\n",
    "df_ts['tip_percentage'] = (df_ts['tip_amount'] / df_ts['fare_amount']) * 100\n",
    "df_ts['tip_percentage'] = df_ts['tip_percentage'].fillna(0)  # No tip = 0%\n",
    "\n",
    "# Distance category\n",
    "def categorize_distance(dist):\n",
    "    if dist < 1:\n",
    "        return 'Short'\n",
    "    elif dist < 3:\n",
    "        return 'Medium'\n",
    "    elif dist < 10:\n",
    "        return 'Long'\n",
    "    else:\n",
    "        return 'Very Long'\n",
    "\n",
    "df_ts['distance_category'] = df_ts['trip_distance'].apply(categorize_distance)\n",
    "\n",
    "print(\"Derived features created:\")\n",
    "print(df_ts[['speed_mph', 'fare_per_mile', 'tip_percentage', 'distance_category']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272dec4",
   "metadata": {},
   "source": [
    "### Step 2: GroupBy Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76804da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by day of week\n",
    "daily_stats = df_ts.groupby('day_name').agg({\n",
    "    'fare_amount': ['mean', 'median', 'std', 'count'],\n",
    "    'trip_distance': ['mean', 'median'],\n",
    "    'trip_duration': ['mean', 'median'],\n",
    "    'passenger_count': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Statistics by Day of Week:\")\n",
    "display(daily_stats)\n",
    "\n",
    "# Aggregate by multiple dimensions: day of week and time of day\n",
    "multi_agg = df_ts.groupby(['day_name', 'time_of_day']).agg({\n",
    "    'fare_amount': 'mean',\n",
    "    'trip_distance': 'count'  # Count of trips\n",
    "}).rename(columns={'fare_amount': 'avg_fare', 'trip_distance': 'trip_count'})\n",
    "\n",
    "print(\"\\nAverage Fare by Day and Time:\")\n",
    "display(multi_agg.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743dcc60",
   "metadata": {},
   "source": [
    "### Step 3: Rolling Window Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfafcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to hourly for rolling calculations\n",
    "hourly_trips = df_ts.resample('h').agg({\n",
    "    'fare_amount': ['mean', 'count'],\n",
    "    'trip_distance': 'mean',\n",
    "    'total_amount': 'sum'\n",
    "})\n",
    "hourly_trips.columns = ['fare_amount', 'trip_count', 'trip_distance', 'total_amount']\n",
    "hourly_trips = hourly_trips[['fare_amount', 'trip_distance', 'total_amount', 'trip_count']]\n",
    "\n",
    "# Calculate rolling averages (7-day and 30-day windows)\n",
    "hourly_trips['fare_7d_avg'] = hourly_trips['fare_amount'].rolling(window=7*24, min_periods=1).mean()  # 7 days * 24 hours\n",
    "hourly_trips['fare_30d_avg'] = hourly_trips['fare_amount'].rolling(window=30*24, min_periods=1).mean()  # 30 days * 24 hours\n",
    "\n",
    "# Calculate exponentially weighted moving average\n",
    "hourly_trips['fare_ewm'] = hourly_trips['fare_amount'].ewm(span=7*24, adjust=False).mean()\n",
    "\n",
    "print(\"Rolling window calculations:\")\n",
    "display(hourly_trips[['fare_amount', 'fare_7d_avg', 'fare_30d_avg', 'fare_ewm']].head(20))\n",
    "\n",
    "# Visualize rolling averages\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(hourly_trips.index, hourly_trips['fare_amount'], alpha=0.3, label='Hourly Average', linewidth=1)\n",
    "plt.plot(hourly_trips.index, hourly_trips['fare_7d_avg'], label='7-Day Rolling Average', linewidth=2)\n",
    "plt.plot(hourly_trips.index, hourly_trips['fare_30d_avg'], label='30-Day Rolling Average', linewidth=2)\n",
    "plt.plot(hourly_trips.index, hourly_trips['fare_ewm'], label='Exponentially Weighted', linewidth=2, linestyle='--')\n",
    "plt.title('Fare Amount Trends with Rolling Averages', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Fare Amount ($)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f55739",
   "metadata": {},
   "source": [
    "### Step 4: Time-Based Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916dae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by hour of day (across all days)\n",
    "hourly_pattern = df_ts.groupby('hour').agg({\n",
    "    'fare_amount': ['mean', 'count'],\n",
    "    'trip_distance': 'mean',\n",
    "    'total_amount': 'sum'\n",
    "})\n",
    "hourly_pattern.columns = ['fare_amount', 'trip_count', 'trip_distance', 'total_amount']\n",
    "hourly_pattern = hourly_pattern[['fare_amount', 'trip_count', 'trip_distance', 'total_amount']]\n",
    "\n",
    "print(\"Hourly Patterns (aggregated across all days):\")\n",
    "display(hourly_pattern.head(10))\n",
    "\n",
    "# Visualize hourly patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Hourly Patterns in Taxi Trips', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Average fare by hour\n",
    "axes[0, 0].plot(hourly_pattern.index, hourly_pattern['fare_amount'], marker='o', linewidth=2)\n",
    "axes[0, 0].set_title('Average Fare by Hour of Day')\n",
    "axes[0, 0].set_xlabel('Hour')\n",
    "axes[0, 0].set_ylabel('Average Fare ($)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trip count by hour\n",
    "axes[0, 1].bar(hourly_pattern.index, hourly_pattern['trip_count'], alpha=0.7)\n",
    "axes[0, 1].set_title('Number of Trips by Hour of Day')\n",
    "axes[0, 1].set_xlabel('Hour')\n",
    "axes[0, 1].set_ylabel('Number of Trips')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Average distance by hour\n",
    "axes[1, 0].plot(hourly_pattern.index, hourly_pattern['trip_distance'], marker='s', color='green', linewidth=2)\n",
    "axes[1, 0].set_title('Average Distance by Hour of Day')\n",
    "axes[1, 0].set_xlabel('Hour')\n",
    "axes[1, 0].set_ylabel('Average Distance (miles)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Total revenue by hour\n",
    "axes[1, 1].bar(hourly_pattern.index, hourly_pattern['total_amount'], alpha=0.7, color='orange')\n",
    "axes[1, 1].set_title('Total Revenue by Hour of Day')\n",
    "axes[1, 1].set_xlabel('Hour')\n",
    "axes[1, 1].set_ylabel('Total Revenue ($)')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb24de94",
   "metadata": {},
   "source": [
    "### Step 5: Cross-Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaba6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation: Day of week vs Time of day\n",
    "crosstab = pd.crosstab(\n",
    "    df_ts['day_name'],\n",
    "    df_ts['time_of_day'],\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(\"Trip Count: Day of Week × Time of Day\")\n",
    "display(crosstab)\n",
    "\n",
    "# Cross-tabulation with aggregation\n",
    "crosstab_fare = pd.crosstab(\n",
    "    df_ts['day_name'],\n",
    "    df_ts['time_of_day'],\n",
    "    values=df_ts['fare_amount'],\n",
    "    aggfunc='mean',\n",
    "    margins=True\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nAverage Fare: Day of Week × Time of Day\")\n",
    "display(crosstab_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79161b",
   "metadata": {},
   "source": [
    "### Step 6: Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f093c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to make pickup_datetime a regular column again\n",
    "df_processed = df_ts.reset_index()\n",
    "\n",
    "# Save processed dataset for next notebook\n",
    "df_processed.to_csv('../output/02_processed_taxi_data.csv', index=False)\n",
    "print(f\"\\nProcessed data saved: {len(df_processed):,} trips\")\n",
    "print(f\"Columns: {df_processed.shape[1]}\")\n",
    "print(\"\\nReady for next phase: Pattern Analysis & Modeling Prep!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1b39f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What we accomplished:**\n",
    "\n",
    "1. ✅ **Set datetime index** for time-based operations\n",
    "2. ✅ **Extracted time-based features** (hour, day, month, etc.)\n",
    "3. ✅ **Merged zone lookup data** using pandas merge\n",
    "4. ✅ **Reshaped data** using pivot and melt\n",
    "5. ✅ **Created derived features** (speed, fare per mile, etc.)\n",
    "6. ✅ **Performed aggregations** by multiple dimensions\n",
    "7. ✅ **Calculated rolling windows** for trend analysis\n",
    "8. ✅ **Created time-based patterns** and visualizations\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Datetime indexing enables time-based operations and aggregations\n",
    "- Merging enriches data with additional context\n",
    "- Feature engineering creates predictive signals\n",
    "- Rolling windows reveal trends and patterns\n",
    "- GroupBy aggregations summarize data at different levels\n",
    "\n",
    "**Next:** Notebook 3 will focus on pattern analysis, advanced visualizations, and preparing data for modeling.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
