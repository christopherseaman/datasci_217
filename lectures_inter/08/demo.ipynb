{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas numpy matplotlib seaborn statsmodels scikit-learn patsy tensorflow keras pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Brief examples of time series operations\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Generate sample time series data\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', periods=365, freq='D')\n",
    "trend = np.linspace(0, 10, 365)\n",
    "seasonal = 5 * np.sin(2 * np.pi * np.arange(365) / 30)  # 30-day seasonality\n",
    "noise = np.random.normal(0, 1, 365)\n",
    "data = trend + seasonal + noise\n",
    "\n",
    "# Create time series\n",
    "ts = pd.Series(data, index=dates)\n",
    "\n",
    "# DateTime operations\n",
    "print(\"\\n=== DateTime Operations ===\")\n",
    "ts_ny = pd.Timestamp('2023-01-01').tz_localize('America/New_York')\n",
    "print(f\"NY Time: {ts_ny}\")\n",
    "print(f\"UTC Time: {ts_ny.tz_convert('UTC')}\")\n",
    "\n",
    "# Resampling\n",
    "print(\"\\n=== Resampling ===\")\n",
    "monthly_mean = ts.resample('ME').mean()\n",
    "print(\"Monthly averages:\", monthly_mean.head())\n",
    "\n",
    "# Rolling windows\n",
    "print(\"\\n=== Rolling Windows ===\")\n",
    "rolling_mean = ts.rolling(window=7).mean()\n",
    "print(\"7-day rolling average:\", rolling_mean.head())\n",
    "\n",
    "# Time series decomposition\n",
    "print(\"\\n=== Decomposition ===\")\n",
    "decomposition = seasonal_decompose(ts, period=30)\n",
    "components = {\n",
    "    'Trend': decomposition.trend.iloc[0],\n",
    "    'Seasonal': decomposition.seasonal.iloc[0],\n",
    "    'Residual': decomposition.resid.iloc[0]\n",
    "}\n",
    "print(\"Components:\", components)\n",
    "\n",
    "# Optional: Plot components\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 10))\n",
    "ts.plot(ax=ax1, title='Original')\n",
    "decomposition.trend.plot(ax=ax2, title='Trend')\n",
    "decomposition.seasonal.plot(ax=ax3, title='Seasonal')\n",
    "decomposition.resid.plot(ax=ax4, title='Residual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Brief examples of statsmodels usage\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 3)  # 3 features\n",
    "y = 2 * X[:, 0] + 3 * X[:, 1] - X[:, 2] + np.random.randn(100)\n",
    "\n",
    "# Linear regression\n",
    "print(\"\\n=== Linear Regression ===\")\n",
    "X_with_const = sm.add_constant(X)\n",
    "model = OLS(y, X_with_const)  # Using direct OLS import\n",
    "results = model.fit()\n",
    "print(results.summary().tables[1])  # Coefficient table\n",
    "\n",
    "# GLM example\n",
    "print(\"\\n=== GLM ===\")\n",
    "# Binary outcome for logistic regression\n",
    "y_binary = (y > y.mean()).astype(int)\n",
    "glm_model = sm.GLM(y_binary, X_with_const, family=sm.families.Binomial())\n",
    "glm_results = glm_model.fit()\n",
    "print(\"GLM coefficients:\", glm_results.params)\n",
    "\n",
    "# Panel data example\n",
    "print(\"\\n=== Panel Data ===\")\n",
    "# Generate panel data\n",
    "entities = 10\n",
    "times = 5\n",
    "panel_idx = pd.MultiIndex.from_product([range(entities), range(times)],\n",
    "                                     names=['entity', 'time'])\n",
    "panel_data = pd.DataFrame({\n",
    "    'y': np.random.randn(entities * times),\n",
    "    'x1': np.random.randn(entities * times)\n",
    "}, index=panel_idx)\n",
    "\n",
    "# Removing panel regression temporarily as PanelOLS location needs verification\n",
    "print(\"Panel regression example temporarily removed\")\n",
    "\n",
    "# Robust regression\n",
    "print(\"\\n=== Robust Regression ===\")\n",
    "rlm_model = sm.RLM(y, X_with_const)\n",
    "rlm_results = rlm_model.fit()\n",
    "print(\"Robust regression coefficients:\", rlm_results.params)\n",
    "\n",
    "# Optional: Diagnostic plots\n",
    "import matplotlib.pyplot as plt\n",
    "fig = sm.graphics.plot_regress_exog(results, 'x1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Brief examples of scikit-learn usage\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 20)  # 20 features\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)  # Binary classification\n",
    "X_cat = np.random.choice(['A', 'B', 'C'], size=(1000, 2))  # Categorical features\n",
    "\n",
    "# Preprocessing\n",
    "print(\"\\n=== Preprocessing ===\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Scaled data mean:\", X_scaled.mean(axis=0)[:3])\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = enc.fit_transform(X_cat)\n",
    "print(\"Encoded categories:\", enc.categories_)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)\n",
    "\n",
    "# Classification example\n",
    "print(\"\\n=== Classification ===\")\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Cross-validation\n",
    "print(\"\\n=== Cross-validation ===\")\n",
    "scores = cross_val_score(clf, X_scaled, y, cv=5)\n",
    "print(\"CV scores:\", scores)\n",
    "\n",
    "# Pipeline example\n",
    "print(\"\\n=== Pipeline ===\")\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "pipe.fit(X, y)\n",
    "print(\"Pipeline score:\", pipe.score(X, y))\n",
    "\n",
    "# Dimensionality reduction\n",
    "print(\"\\n=== PCA ===\")\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Optional: Plot PCA results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y)\n",
    "plt.title('PCA visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Brief examples of Patsy usage\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'y': np.random.randn(100),\n",
    "    'x1': np.random.randn(100),\n",
    "    'x2': np.random.randn(100),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], 100)\n",
    "})\n",
    "\n",
    "# Basic formula\n",
    "print(\"\\n=== Basic Formula ===\")\n",
    "y, X = patsy.dmatrices('y ~ x1 + x2', data)\n",
    "print(\"Design matrix shape:\", X.shape)\n",
    "\n",
    "# Transformations\n",
    "print(\"\\n=== Transformations ===\")\n",
    "y, X = patsy.dmatrices('y ~ standardize(x1) + center(x2)', data)\n",
    "print(\"Transformed x1 mean:\", X[:, 1].mean())\n",
    "print(\"Transformed x2 mean:\", X[:, 2].mean())\n",
    "\n",
    "# Categorical variables\n",
    "print(\"\\n=== Categorical Variables ===\")\n",
    "y, X = patsy.dmatrices('y ~ C(category)', data)\n",
    "print(\"Category design matrix:\\n\", X)\n",
    "\n",
    "# Interactions\n",
    "print(\"\\n=== Interactions ===\")\n",
    "y, X = patsy.dmatrices('y ~ x1 + x2 + x1:x2', data)\n",
    "print(\"Interaction design matrix shape:\", X.shape)\n",
    "\n",
    "# Custom transformations\n",
    "print(\"\\n=== Custom Transformations ===\")\n",
    "def log_plus_1(x):\n",
    "    return np.log(x - x.min() + 1)\n",
    "\n",
    "y, X = patsy.dmatrices('y ~ log_plus_1(x1)', data)\n",
    "print(\"Custom transformation result:\", X[:, 1][:5])\n",
    "\n",
    "# Integration with statsmodels\n",
    "print(\"\\n=== Statsmodels Integration ===\")\n",
    "model = sm.OLS.from_formula('y ~ x1 + x2', data)\n",
    "results = model.fit()\n",
    "print(results.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Brief examples of Keras usage\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(1000, 28, 28, 1)  # Simulated MNIST-like data\n",
    "y = np.random.randint(0, 10, 1000)  # 10 classes\n",
    "\n",
    "# Sequential API example\n",
    "def create_sequential_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Functional API example\n",
    "def create_functional_model():\n",
    "    inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = keras.layers.MaxPooling2D(2)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "# Custom model example\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.pool = keras.layers.MaxPooling2D(2)\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.dense = keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.dense(x)\n",
    "\n",
    "# Data preprocessing\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "# Train sequential model\n",
    "model = create_sequential_model()\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Add callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=3),\n",
    "    keras.callbacks.ModelCheckpoint('best_model.h5'),\n",
    "    keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "\n",
    "# Train with data augmentation\n",
    "model.fit(datagen.flow(X, y, batch_size=32),\n",
    "            epochs=5,\n",
    "            callbacks=callbacks)\n",
    "\n",
    "# Save and load model\n",
    "model.save('sequential_model.h5')\n",
    "loaded_model = keras.models.load_model('sequential_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Brief examples of PyTorch usage\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "X = torch.FloatTensor(np.random.randn(1000, 1, 28, 28))  # Simulated MNIST-like data\n",
    "y = torch.LongTensor(np.random.randint(0, 10, 1000))  # 10 classes\n",
    "\n",
    "# Custom dataset\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create data loader\n",
    "dataset = SimpleDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Linear(64 * 7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, loader, epochs=2):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = SimpleCNN()\n",
    "    train_model(model, loader)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), 'simple_cnn.pt')\n",
    "    \n",
    "    # Load model\n",
    "    new_model = SimpleCNN()\n",
    "    new_model.load_state_dict(torch.load('simple_cnn.pt'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
