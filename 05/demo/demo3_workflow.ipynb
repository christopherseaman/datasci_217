{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d080f25c",
   "metadata": {},
   "source": [
    "# Complete Data Cleaning Workflow\n",
    "\n",
    "End-to-end cleaning pipeline: detect → handle → validate → transform → save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Complete workflow tools loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cc136",
   "metadata": {},
   "source": [
    "## Load Dirty E-commerce Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realistic e-commerce data with multiple issues\n",
    "ecommerce_data = \"\"\"order_id,customer,product_name,price,quantity,order_date,status\n",
    "O001,John Doe,  Widget A  ,29.99,2,2024-01-15,complete\n",
    "O002,JANE SMITH,Widget B,-1,1,2024-01-16,COMPLETE\n",
    "O003,john doe,widget a,29.99,,2024-XX-17,pending\n",
    "O004,Bob Jones,Widget C,19.99,5,2024-01-18,Complete\n",
    "O005,Jane Smith,Widget B,49.99,3,2024-01-19,cancelled\n",
    "O006,BOB JONES,  ,35.50,2,2024-01-20,complete\"\"\"\n",
    "\n",
    "with open('orders_dirty.csv', 'w') as f:\n",
    "    f.write(ecommerce_data)\n",
    "\n",
    "df = pd.read_csv('orders_dirty.csv')\n",
    "print(\"Dirty e-commerce data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eed1bf",
   "metadata": {},
   "source": [
    "## Detect Issues (Audit Data Quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d73668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Duplicates (same customer + product + date)\n",
    "print(f\"\\n=== DUPLICATES ===\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Data issues\n",
    "print(\"\\n=== DATA ISSUES ===\")\n",
    "print(f\"Negative prices: {(df['price'] < 0).sum()}\")\n",
    "print(f\"Missing quantities: {df['quantity'].isnull().sum()}\")\n",
    "print(f\"Invalid dates: {df['order_date'].str.contains('XX', na=False).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5ab2b",
   "metadata": {},
   "source": [
    "## Handle Issues Systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77243252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Fix customer names (standardize)\n",
    "df_clean['customer'] = df_clean['customer'].str.strip().str.title()\n",
    "\n",
    "# 2. Fix product names (strip whitespace, title case)\n",
    "df_clean['product_name'] = df_clean['product_name'].str.strip().str.title()\n",
    "\n",
    "# 3. Replace negative prices with NaN, then fill with median\n",
    "df_clean.loc[df_clean['price'] < 0, 'price'] = np.nan\n",
    "df_clean['price'] = df_clean['price'].fillna(df_clean['price'].median())\n",
    "\n",
    "# 4. Fill missing quantities with 1\n",
    "df_clean['quantity'] = df_clean['quantity'].fillna(1)\n",
    "\n",
    "# 5. Fix dates - replace invalid with NaT\n",
    "df_clean['order_date'] = pd.to_datetime(df_clean['order_date'], errors='coerce')\n",
    "\n",
    "# 6. Standardize status\n",
    "df_clean['status'] = df_clean['status'].str.lower().str.strip()\n",
    "\n",
    "print(\"\\n=== CLEANED DATA ===\")\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e7887",
   "metadata": {},
   "source": [
    "## Validate Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b112c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation checks\n",
    "print(\"\\n=== VALIDATION ===\")\n",
    "print(f\"Missing values remaining: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"Negative prices: {(df_clean['price'] < 0).sum()}\")\n",
    "print(f\"Missing quantities: {df_clean['quantity'].isnull().sum()}\")\n",
    "\n",
    "# Verify data quality improved\n",
    "print(f\"\\nData types:\\n{df_clean.dtypes}\")\n",
    "print(f\"\\nUnique statuses: {df_clean['status'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905222f",
   "metadata": {},
   "source": [
    "## Transform for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calculated fields\n",
    "df_clean['total_price'] = df_clean['quantity'] * df_clean['price']\n",
    "df_clean['order_month'] = df_clean['order_date'].dt.to_period('M')\n",
    "\n",
    "# Create customer spending summary\n",
    "customer_summary = df_clean.groupby('customer').agg({\n",
    "    'order_id': 'count',\n",
    "    'total_price': 'sum'\n",
    "}).rename(columns={'order_id': 'num_orders', 'total_price': 'total_spent'})\n",
    "\n",
    "print(\"\\n=== CUSTOMER SUMMARY ===\")\n",
    "print(customer_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083f761",
   "metadata": {},
   "source": [
    "## Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR method for outlier detection\n",
    "Q1 = df_clean['total_price'].quantile(0.25)\n",
    "Q3 = df_clean['total_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df_clean[(df_clean['total_price'] < Q1 - 1.5 * IQR) |\n",
    "                     (df_clean['total_price'] > Q3 + 1.5 * IQR)]\n",
    "\n",
    "print(f\"\\nOutlier orders: {len(outliers)}\")\n",
    "if len(outliers) > 0:\n",
    "    print(outliers[['order_id', 'customer', 'total_price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f3933",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa960f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df_clean.to_csv('orders_clean.csv', index=False)\n",
    "print(\"\\n✓ Saved orders_clean.csv\")\n",
    "\n",
    "# Save summary\n",
    "customer_summary.to_csv('customer_summary.csv')\n",
    "print(\"✓ Saved customer_summary.csv\")\n",
    "\n",
    "# Create data quality report\n",
    "report = f\"\"\"DATA CLEANING REPORT\n",
    "====================\n",
    "\n",
    "Original rows: {len(df)}\n",
    "Cleaned rows: {len(df_clean)}\n",
    "Rows removed: {len(df) - len(df_clean)}\n",
    "\n",
    "Issues fixed:\n",
    "- Standardized {df['customer'].nunique()} customer names\n",
    "- Fixed {(df['price'] < 0).sum()} negative prices\n",
    "- Filled {df['quantity'].isnull().sum()} missing quantities\n",
    "- Corrected {df['order_date'].str.contains('XX', na=False).sum()} invalid dates\n",
    "\n",
    "Final data quality:\n",
    "- Missing values: {df_clean.isnull().sum().sum()}\n",
    "- Duplicate rows: {df_clean.duplicated().sum()}\n",
    "- Outliers detected: {len(outliers)}\n",
    "\"\"\"\n",
    "\n",
    "with open('cleaning_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print(\"✓ Saved cleaning_report.txt\")\n",
    "\n",
    "print(\"\\n=== WORKFLOW COMPLETE ===\")\n",
    "print(\"All files saved. Data is clean and ready for analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
