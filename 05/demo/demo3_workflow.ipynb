{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d080f25c",
   "metadata": {},
   "source": [
    "# Complete Data Cleaning Workflow\n",
    "\n",
    "End-to-end cleaning pipeline: detect → handle → validate → transform → save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Complete workflow tools loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35cc136",
   "metadata": {},
   "source": [
    "## Load Dirty E-commerce Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458626f",
   "metadata": {},
   "outputs": [],
   "source": "# Realistic e-commerce data with multiple issues\necommerce_data = \"\"\"order_id,customer,product_name,price,quantity,order_date,status\nO001,John Doe,  Widget A  ,29.99,2,2024-01-15,complete\nO002,JANE SMITH,Widget B,-1,1,2024-01-16,COMPLETE\nO003,john doe,widget a,29.99,,2024-XX-17,pending\nO004,Bob Jones,Widget C,19.99,5,2024-01-18,Complete\nO005,Jane Smith,Widget B,49.99,3,2024-01-19,cancelled\nO006,BOB JONES,  ,35.50,2,2024-01-20,complete\"\"\"\n\nimport os\nos.makedirs('output', exist_ok=True)\nwith open('output/orders_dirty.csv', 'w') as f:\n    f.write(ecommerce_data)\n\ndf = pd.read_csv('output/orders_dirty.csv')\nprint(\"Dirty e-commerce data:\")\nprint(df)"
  },
  {
   "cell_type": "markdown",
   "id": "b3eed1bf",
   "metadata": {},
   "source": [
    "## Detect Issues (Audit Data Quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d73668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Duplicates (same customer + product + date)\n",
    "print(f\"\\n=== DUPLICATES ===\")\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# Data issues\n",
    "print(\"\\n=== DATA ISSUES ===\")\n",
    "print(f\"Negative prices: {(df['price'] < 0).sum()}\")\n",
    "print(f\"Missing quantities: {df['quantity'].isnull().sum()}\")\n",
    "print(f\"Invalid dates: {df['order_date'].str.contains('XX', na=False).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5ab2b",
   "metadata": {},
   "source": [
    "## Handle Issues Systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77243252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Fix customer names (standardize)\n",
    "df_clean['customer'] = df_clean['customer'].str.strip().str.title()\n",
    "\n",
    "# 2. Fix product names (strip whitespace, title case)\n",
    "df_clean['product_name'] = df_clean['product_name'].str.strip().str.title()\n",
    "\n",
    "# 3. Replace negative prices with NaN, then fill with median\n",
    "df_clean.loc[df_clean['price'] < 0, 'price'] = np.nan\n",
    "df_clean['price'] = df_clean['price'].fillna(df_clean['price'].median())\n",
    "\n",
    "# 4. Fill missing quantities with 1\n",
    "df_clean['quantity'] = df_clean['quantity'].fillna(1)\n",
    "\n",
    "# 5. Fix dates - replace invalid with NaT\n",
    "df_clean['order_date'] = pd.to_datetime(df_clean['order_date'], errors='coerce')\n",
    "\n",
    "# 6. Standardize status\n",
    "df_clean['status'] = df_clean['status'].str.lower().str.strip()\n",
    "\n",
    "print(\"\\n=== CLEANED DATA ===\")\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e7887",
   "metadata": {},
   "source": [
    "## Validate Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b112c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation checks\n",
    "print(\"\\n=== VALIDATION ===\")\n",
    "print(f\"Missing values remaining: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"Negative prices: {(df_clean['price'] < 0).sum()}\")\n",
    "print(f\"Missing quantities: {df_clean['quantity'].isnull().sum()}\")\n",
    "\n",
    "# Verify data quality improved\n",
    "print(f\"\\nData types:\\n{df_clean.dtypes}\")\n",
    "print(f\"\\nUnique statuses: {df_clean['status'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c905222f",
   "metadata": {},
   "source": [
    "## Transform for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calculated fields\n",
    "df_clean['total_price'] = df_clean['quantity'] * df_clean['price']\n",
    "df_clean['order_month'] = df_clean['order_date'].dt.to_period('M')\n",
    "\n",
    "# Create customer spending summary\n",
    "customer_summary = df_clean.groupby('customer').agg({\n",
    "    'order_id': 'count',\n",
    "    'total_price': 'sum'\n",
    "}).rename(columns={'order_id': 'num_orders', 'total_price': 'total_spent'})\n",
    "\n",
    "print(\"\\n=== CUSTOMER SUMMARY ===\")\n",
    "print(customer_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083f761",
   "metadata": {},
   "source": [
    "## Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff3790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR method for outlier detection\n",
    "Q1 = df_clean['total_price'].quantile(0.25)\n",
    "Q3 = df_clean['total_price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = df_clean[(df_clean['total_price'] < Q1 - 1.5 * IQR) |\n",
    "                     (df_clean['total_price'] > Q3 + 1.5 * IQR)]\n",
    "\n",
    "print(f\"\\nOutlier orders: {len(outliers)}\")\n",
    "if len(outliers) > 0:\n",
    "    print(outliers[['order_id', 'customer', 'total_price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f3933",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa960f35",
   "metadata": {},
   "outputs": [],
   "source": "# Save cleaned data\ndf_clean.to_csv('output/orders_clean.csv', index=False)\nprint(\"\\n✓ Saved output/orders_clean.csv\")\n\n# Save summary\ncustomer_summary.to_csv('output/customer_summary.csv')\nprint(\"✓ Saved output/customer_summary.csv\")\n\n# Create data quality report\nreport = f\"\"\"DATA CLEANING REPORT\n====================\n\nOriginal rows: {len(df)}\nCleaned rows: {len(df_clean)}\nRows removed: {len(df) - len(df_clean)}\n\nIssues fixed:\n- Standardized {df['customer'].nunique()} customer names\n- Fixed {(df['price'] < 0).sum()} negative prices\n- Filled {df['quantity'].isnull().sum()} missing quantities\n- Corrected {df['order_date'].str.contains('XX', na=False).sum()} invalid dates\n\nFinal data quality:\n- Missing values: {df_clean.isnull().sum().sum()}\n- Duplicate rows: {df_clean.duplicated().sum()}\n- Outliers detected: {len(outliers)}\n\"\"\"\n\nwith open('output/cleaning_report.txt', 'w') as f:\n    f.write(report)\nprint(\"✓ Saved output/cleaning_report.txt\")\n\nprint(\"\\n=== WORKFLOW COMPLETE ===\")\nprint(\"All files saved. Data is clean and ready for analysis!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}