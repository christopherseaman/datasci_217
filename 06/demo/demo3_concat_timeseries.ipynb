{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a9b1f3",
   "metadata": {},
   "source": [
    "# Demo 3: Time Series Concatenation and Index Management\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Concatenate DataFrames vertically (stacking rows) and horizontally (adding columns)\n",
    "- Understand when to use `ignore_index=True` vs preserving indexes\n",
    "- Master `set_index()` and `reset_index()` for index manipulation\n",
    "- Handle misaligned indexes during concatenation\n",
    "- Combine `concat()` and `merge()` in practical workflows\n",
    "- Work with time-based indexes for temporal data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692fd35a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a32ab55",
   "metadata": {},
   "source": [
    "## Create Sample Data: Quarterly Sales Reports\n",
    "\n",
    "We'll simulate monthly sales data that arrives in separate quarterly files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2de144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Sales (Jan-Mar 2023)\n",
    "q1_sales = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01']),\n",
    "    'revenue': [125000, 132000, 145000],\n",
    "    'units_sold': [1250, 1320, 1450],\n",
    "    'returns': [50, 45, 60]\n",
    "})\n",
    "\n",
    "# Q2 Sales (Apr-Jun 2023)\n",
    "q2_sales = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-04-01', '2023-05-01', '2023-06-01']),\n",
    "    'revenue': [158000, 165000, 178000],\n",
    "    'units_sold': [1580, 1650, 1780],\n",
    "    'returns': [55, 70, 65]\n",
    "})\n",
    "\n",
    "# Q3 Sales (Jul-Sep 2023)\n",
    "q3_sales = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-07-01', '2023-08-01', '2023-09-01']),\n",
    "    'revenue': [185000, 192000, 175000],\n",
    "    'units_sold': [1850, 1920, 1750],\n",
    "    'returns': [80, 75, 68]\n",
    "})\n",
    "\n",
    "print(\"Q1 Sales:\")\n",
    "display(q1_sales)\n",
    "print(\"\\nQ2 Sales:\")\n",
    "display(q2_sales)\n",
    "print(\"\\nQ3 Sales:\")\n",
    "display(q3_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef758dd2",
   "metadata": {},
   "source": [
    "**Scenario:** You receive quarterly sales files and need to combine them into a single dataset for annual analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87377039",
   "metadata": {},
   "source": [
    "## Vertical Concatenation: Stacking Rows\n",
    "\n",
    "Use `pd.concat()` to stack DataFrames vertically (add more rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b7ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic vertical concatenation\n",
    "year_sales = pd.concat([q1_sales, q2_sales, q3_sales])\n",
    "\n",
    "print(\"Combined Sales (Default):\")\n",
    "year_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8d5fc",
   "metadata": {},
   "source": [
    "**Problem:** Notice the index! It repeats (0, 1, 2, 0, 1, 2, 0, 1, 2)\n",
    "\n",
    "**Why:** Each DataFrame has its own 0-2 index, and concat preserved them.\n",
    "\n",
    "**Two solutions:**\n",
    "1. Use `ignore_index=True` to create new sequential index\n",
    "2. Use `set_index()` to make month the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b154f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: ignore_index=True for clean sequential index\n",
    "year_sales_clean = pd.concat([q1_sales, q2_sales, q3_sales], ignore_index=True)\n",
    "\n",
    "print(\"Combined Sales (Clean Index):\")\n",
    "year_sales_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aff8f8",
   "metadata": {},
   "source": [
    "**Much better!** Now we have a clean 0-8 index.\n",
    "\n",
    "**When to use `ignore_index=True`:**\n",
    "- When original indexes don't matter (default numeric indexes)\n",
    "- When you want clean sequential numbering\n",
    "- When combining similar datasets from different sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806e3cb",
   "metadata": {},
   "source": [
    "## Using set_index() for Meaningful Row Labels\n",
    "\n",
    "For time series data, the date should be the index!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: Use month as index (better for time series!)\n",
    "year_sales_indexed = pd.concat([q1_sales, q2_sales, q3_sales], ignore_index=True)\n",
    "year_sales_indexed = year_sales_indexed.set_index('month')\n",
    "\n",
    "print(\"Combined Sales (Month as Index):\")\n",
    "year_sales_indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd675e",
   "metadata": {},
   "source": [
    "**Advantages of datetime index:**\n",
    "- Can select by date: `year_sales_indexed.loc['2023-06']`\n",
    "- Easy time-based filtering and resampling\n",
    "- More meaningful than numeric index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Select Q2 data using datetime index\n",
    "q2_data = year_sales_indexed.loc['2023-04':'2023-06']\n",
    "print(\"Q2 Data (using datetime index):\")\n",
    "q2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Calculate quarterly totals\n",
    "quarterly_totals = year_sales_indexed.resample('QE').sum()\n",
    "print(\"\\nQuarterly Totals (resample magic!):\")\n",
    "quarterly_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80fc480",
   "metadata": {},
   "source": [
    "**This is why datetime indexes are powerful for time series!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e9dd99",
   "metadata": {},
   "source": [
    "## Horizontal Concatenation: Adding Columns\n",
    "\n",
    "Use `axis=1` to concatenate side-by-side (adding more columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11edab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional metrics in separate DataFrames\n",
    "# Marketing spend data\n",
    "marketing = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01',\n",
    "                             '2023-04-01', '2023-05-01', '2023-06-01']),\n",
    "    'ad_spend': [12000, 15000, 18000, 20000, 22000, 25000],\n",
    "    'impressions': [500000, 600000, 700000, 800000, 850000, 900000]\n",
    "}).set_index('month')\n",
    "\n",
    "# Customer satisfaction scores\n",
    "satisfaction = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01',\n",
    "                             '2023-04-01', '2023-05-01', '2023-06-01']),\n",
    "    'nps_score': [45, 48, 52, 55, 58, 60],\n",
    "    'survey_responses': [120, 135, 150, 165, 180, 195]\n",
    "}).set_index('month')\n",
    "\n",
    "print(\"Marketing Data:\")\n",
    "display(marketing.head())\n",
    "print(\"\\nSatisfaction Data:\")\n",
    "display(satisfaction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e44c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first 6 months of sales for this example\n",
    "sales_h1 = year_sales_indexed.loc['2023-01':'2023-06']\n",
    "\n",
    "# Horizontal concatenation (add columns)\n",
    "combined_metrics = pd.concat([sales_h1, marketing, satisfaction], axis=1)\n",
    "\n",
    "print(\"Combined Metrics (Horizontal Concat):\")\n",
    "combined_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0dbc2",
   "metadata": {},
   "source": [
    "**What happened:**\n",
    "- All DataFrames aligned by their **month index**\n",
    "- Columns from each DataFrame added side-by-side\n",
    "- Index values matched up automatically\n",
    "\n",
    "**Key insight:** Horizontal concat uses index for alignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df945f31",
   "metadata": {},
   "source": [
    "## Handling Misaligned Indexes\n",
    "\n",
    "What happens when indexes don't match perfectly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with missing/extra months\n",
    "partial_data = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-02-01', '2023-03-01', '2023-04-01', \n",
    "                             '2023-07-01']),  # Missing Jan, May, Jun\n",
    "    'social_engagement': [5000, 5500, 6000, 7000]\n",
    "}).set_index('month')\n",
    "\n",
    "print(\"Partial Data (Missing Some Months):\")\n",
    "display(partial_data)\n",
    "\n",
    "# Concatenate with misaligned indexes\n",
    "combined_misaligned = pd.concat([sales_h1, partial_data], axis=1)\n",
    "print(\"\\nCombined with Misaligned Indexes:\")\n",
    "combined_misaligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163693f3",
   "metadata": {},
   "source": [
    "**Result:** NaN values appear where indexes don't match!\n",
    "\n",
    "**Default behavior:** `join='outer'` keeps all index values from both DataFrames.\n",
    "\n",
    "**Alternative:** Use `join='inner'` to keep only matching indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join - only keep matching months\n",
    "combined_inner = pd.concat([sales_h1, partial_data], axis=1, join='inner')\n",
    "\n",
    "print(\"Combined with Inner Join (Only Matching Months):\")\n",
    "combined_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6776e3",
   "metadata": {},
   "source": [
    "**Now only months present in BOTH DataFrames appear!**\n",
    "\n",
    "**Common pitfall:** Using horizontal concat when you should use merge. If indexes don't align well, consider `pd.merge()` instead!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb4e9ec",
   "metadata": {},
   "source": [
    "## Alternative: combine_first() for Filling Missing Values\n",
    "\n",
    "When you have two DataFrames with overlapping indexes and want to fill missing values, `combine_first()` is simpler than concat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create primary sales data with some missing values (NaN)\n",
    "primary_sales = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01',\n",
    "                             '2023-04-01', '2023-05-01']),\n",
    "    'actual_revenue': [125000, np.nan, 145000, np.nan, 165000],\n",
    "    'units_sold': [1250, np.nan, 1450, np.nan, 1650]\n",
    "}).set_index('month')\n",
    "\n",
    "# Create backup/estimated data\n",
    "estimated_sales = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01',\n",
    "                             '2023-04-01', '2023-05-01', '2023-06-01']),\n",
    "    'actual_revenue': [120000, 130000, 140000, 155000, 160000, 175000],\n",
    "    'units_sold': [1200, 1300, 1400, 1550, 1600, 1750]\n",
    "}).set_index('month')\n",
    "\n",
    "print(\"Primary Sales (with missing data):\")\n",
    "display(primary_sales)\n",
    "print(\"\\nEstimated Sales (backup data):\")\n",
    "display(estimated_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bab49dc",
   "metadata": {},
   "source": [
    "**Scenario:** You have actual sales data but some months are missing. You have estimated/forecast data as backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc596c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use combine_first() to fill missing values\n",
    "filled_sales = primary_sales.combine_first(estimated_sales)\n",
    "\n",
    "print(\"Filled Sales (actual where available, estimated where missing):\")\n",
    "filled_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51c269",
   "metadata": {},
   "source": [
    "**What happened:**\n",
    "- February and April: Used **estimated** values (130000, 155000)\n",
    "- Jan, Mar, May: Kept **actual** values (125000, 145000, 165000)\n",
    "- June: Added from estimated data (175000) - not in primary\n",
    "\n",
    "**How combine_first() works:**\n",
    "1. Starts with primary_sales (the caller DataFrame)\n",
    "2. For each NaN value, looks up value from estimated_sales\n",
    "3. Fills NaN with estimated value if available\n",
    "4. Adds any extra indexes from estimated_sales\n",
    "\n",
    "**vs concat():** Much cleaner syntax for this specific use case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115128b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with concat approach (more complex)\n",
    "concat_result = pd.concat([primary_sales, estimated_sales], axis=1, join='outer')\n",
    "print(\"Concat result (creates duplicate columns):\")\n",
    "display(concat_result)\n",
    "\n",
    "# Would need additional steps to merge columns\n",
    "# This is why combine_first() is better for this use case!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89777b4d",
   "metadata": {},
   "source": [
    "**See the difference?** concat creates duplicate columns, combine_first() merges them intelligently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d683e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world application: Add data quality flags\n",
    "filled_sales['data_source'] = 'actual'\n",
    "filled_sales.loc[primary_sales['actual_revenue'].isna(), 'data_source'] = 'estimated'\n",
    "\n",
    "print(\"Final Dataset with Source Tracking:\")\n",
    "filled_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd402c66",
   "metadata": {},
   "source": [
    "**Best practice:** Always track which values came from estimates vs actuals for transparency!\n",
    "\n",
    "**When to use combine_first():**\n",
    "- Filling missing values from a backup DataFrame\n",
    "- Preferring one data source over another\n",
    "- Combining forecasts with actuals\n",
    "- Merging duplicate datasets with different coverage\n",
    "\n",
    "**When NOT to use combine_first():**\n",
    "- Stacking rows from different time periods (use concat)\n",
    "- Joining by keys other than index (use merge)\n",
    "- Need complex aggregation logic (use fillna with custom functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12458b",
   "metadata": {},
   "source": [
    "## reset_index(): Moving Index Back to Columns\n",
    "\n",
    "Sometimes you need to convert the index back to a regular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eff05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current state: month is the index\n",
    "print(\"Before reset_index():\")\n",
    "display(combined_metrics.head())\n",
    "print(f\"Index name: {combined_metrics.index.name}\")\n",
    "print(f\"Columns: {list(combined_metrics.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89812d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to make month a regular column\n",
    "combined_reset = combined_metrics.reset_index()\n",
    "\n",
    "print(\"\\nAfter reset_index():\")\n",
    "display(combined_reset.head())\n",
    "print(f\"Index: {list(combined_reset.index)}\")\n",
    "print(f\"Columns: {list(combined_reset.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638443f5",
   "metadata": {},
   "source": [
    "**What happened:**\n",
    "- `month` moved from index to a regular column\n",
    "- New default numeric index (0, 1, 2, ...) created\n",
    "\n",
    "**When to use reset_index():**\n",
    "- After groupby operations (groups become index)\n",
    "- Before saving to CSV (indexes aren't always preserved)\n",
    "- When you need the index as a column for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da295701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: drop the index instead of converting to column\n",
    "combined_dropped = combined_metrics.reset_index(drop=True)\n",
    "\n",
    "print(\"reset_index(drop=True) - Index Discarded:\")\n",
    "combined_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b76e2",
   "metadata": {},
   "source": [
    "**Use `drop=True` when:** The index contains no useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a742585a",
   "metadata": {},
   "source": [
    "## Combining concat() and merge() in Workflows\n",
    "\n",
    "Real-world scenarios often require both operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Concatenate quarterly sales files\n",
    "all_sales = pd.concat([q1_sales, q2_sales, q3_sales], ignore_index=True)\n",
    "print(\"Step 1: Concatenated Sales Data\")\n",
    "display(all_sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create product category data\n",
    "# (This would come from a separate database table in reality)\n",
    "products = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01',\n",
    "                             '2023-04-01', '2023-05-01', '2023-06-01',\n",
    "                             '2023-07-01', '2023-08-01', '2023-09-01']),\n",
    "    'top_category': ['Electronics', 'Electronics', 'Clothing',\n",
    "                     'Clothing', 'Electronics', 'Home Goods',\n",
    "                     'Home Goods', 'Electronics', 'Clothing'],\n",
    "    'new_customers': [120, 135, 150, 165, 180, 195, 210, 225, 240]\n",
    "})\n",
    "\n",
    "print(\"\\nStep 2: Product Category Data\")\n",
    "display(products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Merge sales with product data\n",
    "sales_enriched = pd.merge(all_sales, products, on='month', how='left')\n",
    "\n",
    "print(\"\\nStep 3: Merged Sales + Product Data\")\n",
    "display(sales_enriched.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate metrics and analyze\n",
    "sales_enriched['return_rate'] = (sales_enriched['returns'] / \n",
    "                                 sales_enriched['units_sold'] * 100).round(2)\n",
    "sales_enriched['revenue_per_unit'] = (sales_enriched['revenue'] / \n",
    "                                      sales_enriched['units_sold']).round(2)\n",
    "\n",
    "print(\"\\nStep 4: Final Analysis Dataset\")\n",
    "display(sales_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a517562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Analyze by product category\n",
    "category_summary = sales_enriched.groupby('top_category').agg({\n",
    "    'revenue': 'sum',\n",
    "    'units_sold': 'sum',\n",
    "    'new_customers': 'sum',\n",
    "    'return_rate': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "category_summary['avg_revenue_per_unit'] = (\n",
    "    category_summary['revenue'] / category_summary['units_sold']\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nStep 5: Category Summary\")\n",
    "category_summary.sort_values('revenue', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7463a8",
   "metadata": {},
   "source": [
    "**Complete workflow:**\n",
    "1. **concat()** - Combine quarterly files (same structure)\n",
    "2. **merge()** - Add related data from other sources (different structure)\n",
    "3. **groupby()** - Analyze the enriched dataset\n",
    "\n",
    "**Key insight:** concat for stacking, merge for joining!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81346c76",
   "metadata": {},
   "source": [
    "## Tracking Data Sources with keys Parameter\n",
    "\n",
    "Use `keys` to label where data came from during concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate with source labels\n",
    "labeled_sales = pd.concat(\n",
    "    [q1_sales, q2_sales, q3_sales],\n",
    "    keys=['Q1', 'Q2', 'Q3'],\n",
    "    names=['quarter', 'month_index']\n",
    ")\n",
    "\n",
    "print(\"Sales with Quarter Labels (MultiIndex):\")\n",
    "labeled_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bec49",
   "metadata": {},
   "source": [
    "**Created a MultiIndex!**\n",
    "- Outer level: quarter (Q1, Q2, Q3)\n",
    "- Inner level: month_index (0, 1, 2)\n",
    "\n",
    "**Use case:** Track data provenance when combining multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68407156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all Q2 data using the outer index level\n",
    "q2_only = labeled_sales.loc['Q2']\n",
    "print(\"Q2 Data Only:\")\n",
    "q2_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b33d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the MultiIndex with reset_index\n",
    "labeled_flat = labeled_sales.reset_index()\n",
    "print(\"\\nFlattened with Quarter Column:\")\n",
    "labeled_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce7b1f",
   "metadata": {},
   "source": [
    "**Perfect!** Now we have a `quarter` column showing data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492fe3b0",
   "metadata": {},
   "source": [
    "## Real-World Application: Year-Over-Year Analysis\n",
    "\n",
    "Combining techniques to compare 2023 vs 2024 performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc37004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2024 Q1 data for comparison\n",
    "q1_2024 = pd.DataFrame({\n",
    "    'month': pd.to_datetime(['2024-01-01', '2024-02-01', '2024-03-01']),\n",
    "    'revenue': [145000, 152000, 168000],\n",
    "    'units_sold': [1450, 1520, 1680],\n",
    "    'returns': [48, 52, 58]\n",
    "})\n",
    "\n",
    "# Prepare both years with year label\n",
    "q1_2023_labeled = q1_sales.copy()\n",
    "q1_2023_labeled['year'] = 2023\n",
    "\n",
    "q1_2024_labeled = q1_2024.copy()\n",
    "q1_2024_labeled['year'] = 2024\n",
    "\n",
    "# Concatenate both years\n",
    "yoy_data = pd.concat([q1_2023_labeled, q1_2024_labeled], ignore_index=True)\n",
    "\n",
    "# Add month name for grouping\n",
    "yoy_data['month_name'] = yoy_data['month'].dt.strftime('%B')\n",
    "\n",
    "print(\"Year-Over-Year Q1 Data:\")\n",
    "yoy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c66155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to compare 2023 vs 2024 side-by-side\n",
    "yoy_comparison = yoy_data.pivot_table(\n",
    "    index='month_name',\n",
    "    columns='year',\n",
    "    values=['revenue', 'units_sold']\n",
    ")\n",
    "\n",
    "print(\"\\nYear-Over-Year Comparison (Pivoted):\")\n",
    "yoy_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12bd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate growth rates\n",
    "# Flatten column names for easier access\n",
    "yoy_flat = yoy_comparison.copy()\n",
    "yoy_flat.columns = ['_'.join(map(str, col)) for col in yoy_flat.columns]\n",
    "\n",
    "yoy_flat['revenue_growth_%'] = (\n",
    "    (yoy_flat['revenue_2024'] - yoy_flat['revenue_2023']) / \n",
    "    yoy_flat['revenue_2023'] * 100\n",
    ").round(1)\n",
    "\n",
    "yoy_flat['units_growth_%'] = (\n",
    "    (yoy_flat['units_sold_2024'] - yoy_flat['units_sold_2023']) / \n",
    "    yoy_flat['units_sold_2023'] * 100\n",
    ").round(1)\n",
    "\n",
    "print(\"\\nYear-Over-Year Growth Analysis:\")\n",
    "yoy_flat[['revenue_2023', 'revenue_2024', 'revenue_growth_%',\n",
    "          'units_sold_2023', 'units_sold_2024', 'units_growth_%']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60861b2",
   "metadata": {},
   "source": [
    "**Business insights:**\n",
    "- February 2024 revenue up **15.2%** vs 2023\n",
    "- March 2024 shows strongest growth: **15.9%** revenue, **15.9%** units\n",
    "- Consistent growth across all months\n",
    "\n",
    "**Workflow used:**\n",
    "1. **concat()** - Stack 2023 and 2024 data\n",
    "2. **pivot_table()** - Create side-by-side comparison\n",
    "3. Calculate derived metrics (growth rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500fc55e",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **concat() for stacking similar DataFrames:**\n",
    "   - Vertical (`axis=0`): Add more rows (default)\n",
    "   - Horizontal (`axis=1`): Add more columns\n",
    "   - Use `ignore_index=True` for clean sequential indexing\n",
    "\n",
    "2. **set_index() makes columns into indexes:**\n",
    "   - Essential for time series (use dates as index)\n",
    "   - Enables powerful time-based operations\n",
    "   - Makes selection more intuitive\n",
    "\n",
    "3. **reset_index() moves indexes back to columns:**\n",
    "   - After groupby operations\n",
    "   - When saving to files\n",
    "   - Use `drop=True` to discard index\n",
    "\n",
    "4. **Index alignment in horizontal concat:**\n",
    "   - Default: `join='outer'` (keep all indexes)\n",
    "   - Alternative: `join='inner'` (only matching)\n",
    "   - Creates NaN where indexes don't match\n",
    "\n",
    "5. **Common workflow patterns:**\n",
    "   - **concat → set_index:** Stack files then create meaningful index\n",
    "   - **concat → merge:** Stack similar data, then join with related data\n",
    "   - **concat with keys:** Track data sources with MultiIndex\n",
    "\n",
    "6. **When to use concat vs merge:**\n",
    "   - **concat:** Same structure, different time periods/sources\n",
    "   - **merge:** Different structures, need to join by keys\n",
    "\n",
    "7. **Index management best practices:**\n",
    "   - Use datetime indexes for time series\n",
    "   - Use meaningful indexes (not just 0, 1, 2)\n",
    "   - Reset index before groupby results\n",
    "   - Set index for better selection\n",
    "\n",
    "**Practice tip:** Think of concat as \"stacking LEGO bricks\" - vertically or horizontally. Merge is like \"connecting LEGO pieces by their studs\" (keys)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
